{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (12800, 8), target_ratio: 0.502\n",
      "test size: (4000, 8), target_ratio: 0.501\n",
      "dev size: (3200, 8), target_ratio: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but not appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                90        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid (TFOpLambda  (None, 1)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Bias of the last layers:\n",
      "[0.]\n",
      "\n",
      ">>> Kernel of the last layers:\n",
      "[[-0.24726865]\n",
      " [ 0.68438464]\n",
      " [ 0.14847296]\n",
      " [-0.11615735]\n",
      " [-0.13499832]\n",
      " [ 0.06303412]\n",
      " [-0.12831736]\n",
      " [-0.6355281 ]\n",
      " [-0.73033303]\n",
      " [-0.03700101]]\n",
      "\n",
      ">>> Bias of the first layers:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      ">>> Kernel of the first layers:\n",
      "[[ 0.27434552 -0.08809695 -0.34831077  0.05812716 -0.26086658  0.5021044\n",
      "   0.02122277 -0.12708426  0.0413698   0.38695037]\n",
      " [-0.28205135 -0.0381906  -0.54502565 -0.518739    0.57005167 -0.2850911\n",
      "  -0.28100067  0.5341382   0.12164605  0.29330844]\n",
      " [-0.11227959 -0.00172889  0.4041726  -0.1026282   0.18625504  0.16321474\n",
      "   0.05342579 -0.02886128 -0.09993783 -0.2026555 ]\n",
      " [ 0.0565933   0.14265877  0.48244488 -0.14600396  0.26096338  0.13438952\n",
      "   0.48842633  0.32555115 -0.00207978  0.01282179]\n",
      " [ 0.07784826 -0.03354377 -0.31859687 -0.06408441  0.2024464  -0.15602511\n",
      "  -0.38213772  0.4802389   0.04864037 -0.16675308]\n",
      " [ 0.4762888   0.5667201  -0.12803513 -0.37903354 -0.34179136 -0.54581\n",
      "  -0.57404166  0.03842044 -0.07267839 -0.04430187]\n",
      " [-0.41358215  0.5706222   0.35124975  0.36610204  0.57045996 -0.02937156\n",
      "   0.5634965   0.23860443 -0.572986   -0.3937743 ]\n",
      " [ 0.08994776  0.47369134 -0.33376342  0.07893103  0.17889196 -0.45057806\n",
      "  -0.38803566  0.43677974 -0.18004727  0.3089828 ]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:')\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 1ms/step - loss: 0.6496 - auc: 0.6642 - binary_accuracy: 0.6167\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5052 - auc: 0.8566 - binary_accuracy: 0.7827\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4307 - auc: 0.8942 - binary_accuracy: 0.8109\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3784 - auc: 0.9172 - binary_accuracy: 0.8402\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3442 - auc: 0.9299 - binary_accuracy: 0.8583\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3246 - auc: 0.9369 - binary_accuracy: 0.8675\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3120 - auc: 0.9412 - binary_accuracy: 0.8727\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.3031 - auc: 0.9440 - binary_accuracy: 0.8797\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2968 - auc: 0.9463 - binary_accuracy: 0.8820\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2923 - auc: 0.9477 - binary_accuracy: 0.8857\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2887 - auc: 0.9489 - binary_accuracy: 0.8882\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2857 - auc: 0.9499 - binary_accuracy: 0.8901\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2833 - auc: 0.9506 - binary_accuracy: 0.8921\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2813 - auc: 0.9513 - binary_accuracy: 0.8942\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2795 - auc: 0.9518 - binary_accuracy: 0.8947\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2781 - auc: 0.9523 - binary_accuracy: 0.8938\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2767 - auc: 0.9527 - binary_accuracy: 0.8961\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2754 - auc: 0.9532 - binary_accuracy: 0.8962\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2742 - auc: 0.9538 - binary_accuracy: 0.8965\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2731 - auc: 0.9540 - binary_accuracy: 0.8970\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2721 - auc: 0.9544 - binary_accuracy: 0.8985\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2715 - auc: 0.9546 - binary_accuracy: 0.8978\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2704 - auc: 0.9550 - binary_accuracy: 0.8992\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2697 - auc: 0.9552 - binary_accuracy: 0.8988\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2690 - auc: 0.9555 - binary_accuracy: 0.8998\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2682 - auc: 0.9558 - binary_accuracy: 0.8998\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2675 - auc: 0.9558 - binary_accuracy: 0.9001\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2667 - auc: 0.9562 - binary_accuracy: 0.9002\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2663 - auc: 0.9564 - binary_accuracy: 0.9008\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2657 - auc: 0.9566 - binary_accuracy: 0.9025\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2654 - auc: 0.9567 - binary_accuracy: 0.9013\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2647 - auc: 0.9569 - binary_accuracy: 0.9005\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2642 - auc: 0.9571 - binary_accuracy: 0.9015\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2638 - auc: 0.9573 - binary_accuracy: 0.9015\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2634 - auc: 0.9573 - binary_accuracy: 0.9023\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2629 - auc: 0.9576 - binary_accuracy: 0.9015\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2623 - auc: 0.9577 - binary_accuracy: 0.9019\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2621 - auc: 0.9578 - binary_accuracy: 0.9025\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2615 - auc: 0.9580 - binary_accuracy: 0.9041\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2612 - auc: 0.9581 - binary_accuracy: 0.9025\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2610 - auc: 0.9581 - binary_accuracy: 0.9053\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2605 - auc: 0.9584 - binary_accuracy: 0.9035\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2601 - auc: 0.9584 - binary_accuracy: 0.9038\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2596 - auc: 0.9585 - binary_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2594 - auc: 0.9586 - binary_accuracy: 0.9044\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2591 - auc: 0.9587 - binary_accuracy: 0.9055\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2587 - auc: 0.9589 - binary_accuracy: 0.9045\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2582 - auc: 0.9590 - binary_accuracy: 0.9048\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2580 - auc: 0.9590 - binary_accuracy: 0.9051\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2572 - auc: 0.9593 - binary_accuracy: 0.9065\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2574 - auc: 0.9593 - binary_accuracy: 0.9062\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2569 - auc: 0.9593 - binary_accuracy: 0.9059\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2565 - auc: 0.9595 - binary_accuracy: 0.9071\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2562 - auc: 0.9595 - binary_accuracy: 0.9071\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2560 - auc: 0.9596 - binary_accuracy: 0.9060\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2555 - auc: 0.9598 - binary_accuracy: 0.9079\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2552 - auc: 0.9599 - binary_accuracy: 0.9066\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2551 - auc: 0.9600 - binary_accuracy: 0.9075\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2543 - auc: 0.9602 - binary_accuracy: 0.9068\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2543 - auc: 0.9603 - binary_accuracy: 0.9073\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2540 - auc: 0.9602 - binary_accuracy: 0.9072\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2538 - auc: 0.9603 - binary_accuracy: 0.9081\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2534 - auc: 0.9605 - binary_accuracy: 0.9071\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2532 - auc: 0.9605 - binary_accuracy: 0.9081\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2528 - auc: 0.9606 - binary_accuracy: 0.9088\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2523 - auc: 0.9607 - binary_accuracy: 0.9087\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2522 - auc: 0.9607 - binary_accuracy: 0.9082\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2517 - auc: 0.9609 - binary_accuracy: 0.9077\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2514 - auc: 0.9610 - binary_accuracy: 0.9087\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2513 - auc: 0.9610 - binary_accuracy: 0.9093\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2508 - auc: 0.9610 - binary_accuracy: 0.9096\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2506 - auc: 0.9614 - binary_accuracy: 0.9091\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2503 - auc: 0.9612 - binary_accuracy: 0.9085\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2500 - auc: 0.9614 - binary_accuracy: 0.9102\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2498 - auc: 0.9615 - binary_accuracy: 0.9102\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2495 - auc: 0.9615 - binary_accuracy: 0.9100\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2492 - auc: 0.9617 - binary_accuracy: 0.9111\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2489 - auc: 0.9616 - binary_accuracy: 0.9109\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2486 - auc: 0.9617 - binary_accuracy: 0.9099\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2484 - auc: 0.9618 - binary_accuracy: 0.9111\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2481 - auc: 0.9619 - binary_accuracy: 0.9112\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2478 - auc: 0.9620 - binary_accuracy: 0.9107\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2474 - auc: 0.9620 - binary_accuracy: 0.9113\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2472 - auc: 0.9621 - binary_accuracy: 0.9107\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2468 - auc: 0.9622 - binary_accuracy: 0.9118\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2467 - auc: 0.9622 - binary_accuracy: 0.9123\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2463 - auc: 0.9624 - binary_accuracy: 0.9115\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2460 - auc: 0.9624 - binary_accuracy: 0.9120\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2459 - auc: 0.9625 - binary_accuracy: 0.9116\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2454 - auc: 0.9626 - binary_accuracy: 0.9125\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2452 - auc: 0.9626 - binary_accuracy: 0.9124\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2449 - auc: 0.9627 - binary_accuracy: 0.9122\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2447 - auc: 0.9628 - binary_accuracy: 0.9112\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2445 - auc: 0.9628 - binary_accuracy: 0.9122\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2441 - auc: 0.9628 - binary_accuracy: 0.9128\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2437 - auc: 0.9631 - binary_accuracy: 0.9117\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2434 - auc: 0.9631 - binary_accuracy: 0.9123\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2432 - auc: 0.9631 - binary_accuracy: 0.9127\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2430 - auc: 0.9632 - binary_accuracy: 0.9130\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2427 - auc: 0.9632 - binary_accuracy: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c60f4ec70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step - loss: 0.2645 - auc: 0.9553 - binary_accuracy: 0.9060\n",
      "125/125 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.56\n",
      "0 - 0.27\n",
      "0 - 0.52\n",
      "1 - 0.97\n",
      "0 - 0.00\n",
      "0 - 0.02\n",
      "1 - 0.89\n",
      "0 - 0.01\n",
      "1 - 0.95\n",
      "1 - 1.00\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RegularizedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid_1 (TFOpLamb  (None, 1)                0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 2s 2ms/step - loss: 0.6190 - auc_1: 0.7656 - binary_accuracy: 0.6721 - val_loss: 0.4471 - val_auc_1: 0.9062 - val_binary_accuracy: 0.7975\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.4075 - auc_1: 0.9132 - binary_accuracy: 0.8209 - val_loss: 0.3698 - val_auc_1: 0.9300 - val_binary_accuracy: 0.8587\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3586 - auc_1: 0.9330 - binary_accuracy: 0.8584 - val_loss: 0.3350 - val_auc_1: 0.9428 - val_binary_accuracy: 0.8769\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.3275 - auc_1: 0.9449 - binary_accuracy: 0.8777 - val_loss: 0.3104 - val_auc_1: 0.9506 - val_binary_accuracy: 0.8909\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.3076 - auc_1: 0.9518 - binary_accuracy: 0.8894 - val_loss: 0.2960 - val_auc_1: 0.9560 - val_binary_accuracy: 0.8981\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2957 - auc_1: 0.9563 - binary_accuracy: 0.8962 - val_loss: 0.2875 - val_auc_1: 0.9589 - val_binary_accuracy: 0.9019\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2880 - auc_1: 0.9588 - binary_accuracy: 0.8997 - val_loss: 0.2818 - val_auc_1: 0.9609 - val_binary_accuracy: 0.9031\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2828 - auc_1: 0.9608 - binary_accuracy: 0.9024 - val_loss: 0.2787 - val_auc_1: 0.9621 - val_binary_accuracy: 0.9028\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2784 - auc_1: 0.9621 - binary_accuracy: 0.9045 - val_loss: 0.2743 - val_auc_1: 0.9634 - val_binary_accuracy: 0.9053\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2750 - auc_1: 0.9634 - binary_accuracy: 0.9068 - val_loss: 0.2723 - val_auc_1: 0.9639 - val_binary_accuracy: 0.9056\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2720 - auc_1: 0.9642 - binary_accuracy: 0.9071 - val_loss: 0.2684 - val_auc_1: 0.9654 - val_binary_accuracy: 0.9084\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2692 - auc_1: 0.9652 - binary_accuracy: 0.9083 - val_loss: 0.2664 - val_auc_1: 0.9663 - val_binary_accuracy: 0.9075\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2669 - auc_1: 0.9659 - binary_accuracy: 0.9076 - val_loss: 0.2630 - val_auc_1: 0.9675 - val_binary_accuracy: 0.9084\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2645 - auc_1: 0.9669 - binary_accuracy: 0.9098 - val_loss: 0.2603 - val_auc_1: 0.9683 - val_binary_accuracy: 0.9122\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2624 - auc_1: 0.9676 - binary_accuracy: 0.9103 - val_loss: 0.2589 - val_auc_1: 0.9690 - val_binary_accuracy: 0.9119\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2610 - auc_1: 0.9681 - binary_accuracy: 0.9102 - val_loss: 0.2568 - val_auc_1: 0.9694 - val_binary_accuracy: 0.9116\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2589 - auc_1: 0.9689 - binary_accuracy: 0.9112 - val_loss: 0.2552 - val_auc_1: 0.9699 - val_binary_accuracy: 0.9122\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2574 - auc_1: 0.9694 - binary_accuracy: 0.9127 - val_loss: 0.2550 - val_auc_1: 0.9702 - val_binary_accuracy: 0.9128\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2562 - auc_1: 0.9698 - binary_accuracy: 0.9127 - val_loss: 0.2524 - val_auc_1: 0.9709 - val_binary_accuracy: 0.9153\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2550 - auc_1: 0.9703 - binary_accuracy: 0.9137 - val_loss: 0.2523 - val_auc_1: 0.9717 - val_binary_accuracy: 0.9147\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2538 - auc_1: 0.9707 - binary_accuracy: 0.9139 - val_loss: 0.2509 - val_auc_1: 0.9721 - val_binary_accuracy: 0.9156\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2522 - auc_1: 0.9714 - binary_accuracy: 0.9149 - val_loss: 0.2496 - val_auc_1: 0.9722 - val_binary_accuracy: 0.9172\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2510 - auc_1: 0.9718 - binary_accuracy: 0.9178 - val_loss: 0.2493 - val_auc_1: 0.9723 - val_binary_accuracy: 0.9169\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2503 - auc_1: 0.9721 - binary_accuracy: 0.9167 - val_loss: 0.2485 - val_auc_1: 0.9728 - val_binary_accuracy: 0.9159\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2490 - auc_1: 0.9726 - binary_accuracy: 0.9181 - val_loss: 0.2471 - val_auc_1: 0.9733 - val_binary_accuracy: 0.9206\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2484 - auc_1: 0.9730 - binary_accuracy: 0.9202 - val_loss: 0.2465 - val_auc_1: 0.9737 - val_binary_accuracy: 0.9172\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2473 - auc_1: 0.9732 - binary_accuracy: 0.9198 - val_loss: 0.2451 - val_auc_1: 0.9741 - val_binary_accuracy: 0.9225\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2468 - auc_1: 0.9735 - binary_accuracy: 0.9207 - val_loss: 0.2441 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9241\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2460 - auc_1: 0.9740 - binary_accuracy: 0.9217 - val_loss: 0.2448 - val_auc_1: 0.9742 - val_binary_accuracy: 0.9203\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2454 - auc_1: 0.9741 - binary_accuracy: 0.9223 - val_loss: 0.2437 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9206\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2446 - auc_1: 0.9744 - binary_accuracy: 0.9237 - val_loss: 0.2427 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9253\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2439 - auc_1: 0.9748 - binary_accuracy: 0.9234 - val_loss: 0.2423 - val_auc_1: 0.9754 - val_binary_accuracy: 0.9253\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2433 - auc_1: 0.9751 - binary_accuracy: 0.9251 - val_loss: 0.2415 - val_auc_1: 0.9758 - val_binary_accuracy: 0.9281\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2425 - auc_1: 0.9754 - binary_accuracy: 0.9262 - val_loss: 0.2416 - val_auc_1: 0.9757 - val_binary_accuracy: 0.9231\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2419 - auc_1: 0.9756 - binary_accuracy: 0.9256 - val_loss: 0.2399 - val_auc_1: 0.9761 - val_binary_accuracy: 0.9294\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2412 - auc_1: 0.9758 - binary_accuracy: 0.9264 - val_loss: 0.2405 - val_auc_1: 0.9761 - val_binary_accuracy: 0.9278\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2408 - auc_1: 0.9761 - binary_accuracy: 0.9268 - val_loss: 0.2392 - val_auc_1: 0.9761 - val_binary_accuracy: 0.9275\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2402 - auc_1: 0.9763 - binary_accuracy: 0.9274 - val_loss: 0.2381 - val_auc_1: 0.9766 - val_binary_accuracy: 0.9281\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2396 - auc_1: 0.9764 - binary_accuracy: 0.9290 - val_loss: 0.2377 - val_auc_1: 0.9772 - val_binary_accuracy: 0.9300\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2390 - auc_1: 0.9768 - binary_accuracy: 0.9288 - val_loss: 0.2369 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9331\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2383 - auc_1: 0.9771 - binary_accuracy: 0.9290 - val_loss: 0.2370 - val_auc_1: 0.9771 - val_binary_accuracy: 0.9328\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2379 - auc_1: 0.9772 - binary_accuracy: 0.9291 - val_loss: 0.2355 - val_auc_1: 0.9775 - val_binary_accuracy: 0.9322\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2372 - auc_1: 0.9775 - binary_accuracy: 0.9301 - val_loss: 0.2355 - val_auc_1: 0.9777 - val_binary_accuracy: 0.9309\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2365 - auc_1: 0.9776 - binary_accuracy: 0.9305 - val_loss: 0.2352 - val_auc_1: 0.9781 - val_binary_accuracy: 0.9322\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2360 - auc_1: 0.9780 - binary_accuracy: 0.9307 - val_loss: 0.2346 - val_auc_1: 0.9780 - val_binary_accuracy: 0.9341\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2356 - auc_1: 0.9780 - binary_accuracy: 0.9315 - val_loss: 0.2348 - val_auc_1: 0.9782 - val_binary_accuracy: 0.9344\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2350 - auc_1: 0.9784 - binary_accuracy: 0.9321 - val_loss: 0.2336 - val_auc_1: 0.9783 - val_binary_accuracy: 0.9322\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2346 - auc_1: 0.9784 - binary_accuracy: 0.9316 - val_loss: 0.2335 - val_auc_1: 0.9786 - val_binary_accuracy: 0.9312\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2341 - auc_1: 0.9787 - binary_accuracy: 0.9321 - val_loss: 0.2335 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9341\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2338 - auc_1: 0.9786 - binary_accuracy: 0.9336 - val_loss: 0.2335 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9344\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2336 - auc_1: 0.9788 - binary_accuracy: 0.9328 - val_loss: 0.2333 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9347\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2333 - auc_1: 0.9790 - binary_accuracy: 0.9334 - val_loss: 0.2326 - val_auc_1: 0.9784 - val_binary_accuracy: 0.9319\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2331 - auc_1: 0.9789 - binary_accuracy: 0.9330 - val_loss: 0.2328 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9337\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2325 - auc_1: 0.9791 - binary_accuracy: 0.9338 - val_loss: 0.2325 - val_auc_1: 0.9791 - val_binary_accuracy: 0.9356\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2324 - auc_1: 0.9794 - binary_accuracy: 0.9347 - val_loss: 0.2326 - val_auc_1: 0.9787 - val_binary_accuracy: 0.9350\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2318 - auc_1: 0.9795 - binary_accuracy: 0.9349 - val_loss: 0.2330 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9347\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2318 - auc_1: 0.9796 - binary_accuracy: 0.9350 - val_loss: 0.2325 - val_auc_1: 0.9790 - val_binary_accuracy: 0.9350\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2317 - auc_1: 0.9796 - binary_accuracy: 0.9347 - val_loss: 0.2321 - val_auc_1: 0.9792 - val_binary_accuracy: 0.9366\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2311 - auc_1: 0.9799 - binary_accuracy: 0.9362 - val_loss: 0.2328 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9353\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2313 - auc_1: 0.9795 - binary_accuracy: 0.9345 - val_loss: 0.2320 - val_auc_1: 0.9795 - val_binary_accuracy: 0.9356\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2311 - auc_1: 0.9800 - binary_accuracy: 0.9341 - val_loss: 0.2315 - val_auc_1: 0.9793 - val_binary_accuracy: 0.9344\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 1s 1ms/step - loss: 0.2309 - auc_1: 0.9798 - binary_accuracy: 0.9361 - val_loss: 0.2313 - val_auc_1: 0.9797 - val_binary_accuracy: 0.9347\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2310 - auc_1: 0.9799 - binary_accuracy: 0.9356 - val_loss: 0.2316 - val_auc_1: 0.9797 - val_binary_accuracy: 0.9359\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2304 - auc_1: 0.9802 - binary_accuracy: 0.9359 - val_loss: 0.2309 - val_auc_1: 0.9798 - val_binary_accuracy: 0.9366\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2302 - auc_1: 0.9802 - binary_accuracy: 0.9373 - val_loss: 0.2308 - val_auc_1: 0.9797 - val_binary_accuracy: 0.9359\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2303 - auc_1: 0.9803 - binary_accuracy: 0.9353 - val_loss: 0.2312 - val_auc_1: 0.9795 - val_binary_accuracy: 0.9375\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2303 - auc_1: 0.9803 - binary_accuracy: 0.9360 - val_loss: 0.2310 - val_auc_1: 0.9799 - val_binary_accuracy: 0.9369\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2301 - auc_1: 0.9804 - binary_accuracy: 0.9363 - val_loss: 0.2304 - val_auc_1: 0.9801 - val_binary_accuracy: 0.9375\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2299 - auc_1: 0.9804 - binary_accuracy: 0.9362 - val_loss: 0.2307 - val_auc_1: 0.9806 - val_binary_accuracy: 0.9350\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2299 - auc_1: 0.9806 - binary_accuracy: 0.9361 - val_loss: 0.2297 - val_auc_1: 0.9801 - val_binary_accuracy: 0.9347\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2297 - auc_1: 0.9806 - binary_accuracy: 0.9366 - val_loss: 0.2298 - val_auc_1: 0.9806 - val_binary_accuracy: 0.9372\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2297 - auc_1: 0.9808 - binary_accuracy: 0.9370 - val_loss: 0.2303 - val_auc_1: 0.9804 - val_binary_accuracy: 0.9378\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2296 - auc_1: 0.9807 - binary_accuracy: 0.9375 - val_loss: 0.2297 - val_auc_1: 0.9802 - val_binary_accuracy: 0.9369\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2295 - auc_1: 0.9808 - binary_accuracy: 0.9377 - val_loss: 0.2294 - val_auc_1: 0.9804 - val_binary_accuracy: 0.9369\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - auc_1: 0.9808 - binary_accuracy: 0.9370 - val_loss: 0.2310 - val_auc_1: 0.9803 - val_binary_accuracy: 0.9394\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2293 - auc_1: 0.9808 - binary_accuracy: 0.9373 - val_loss: 0.2298 - val_auc_1: 0.9805 - val_binary_accuracy: 0.9388\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9810 - binary_accuracy: 0.9377 - val_loss: 0.2302 - val_auc_1: 0.9801 - val_binary_accuracy: 0.9381\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2291 - auc_1: 0.9811 - binary_accuracy: 0.9373 - val_loss: 0.2294 - val_auc_1: 0.9805 - val_binary_accuracy: 0.9369\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2290 - auc_1: 0.9809 - binary_accuracy: 0.9377 - val_loss: 0.2298 - val_auc_1: 0.9807 - val_binary_accuracy: 0.9362\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9812 - binary_accuracy: 0.9381 - val_loss: 0.2294 - val_auc_1: 0.9804 - val_binary_accuracy: 0.9381\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9810 - binary_accuracy: 0.9377 - val_loss: 0.2293 - val_auc_1: 0.9807 - val_binary_accuracy: 0.9375\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2286 - auc_1: 0.9812 - binary_accuracy: 0.9384 - val_loss: 0.2300 - val_auc_1: 0.9805 - val_binary_accuracy: 0.9372\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2287 - auc_1: 0.9813 - binary_accuracy: 0.9398 - val_loss: 0.2293 - val_auc_1: 0.9805 - val_binary_accuracy: 0.9366\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2285 - auc_1: 0.9813 - binary_accuracy: 0.9386 - val_loss: 0.2291 - val_auc_1: 0.9807 - val_binary_accuracy: 0.9369\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2284 - auc_1: 0.9812 - binary_accuracy: 0.9390 - val_loss: 0.2292 - val_auc_1: 0.9811 - val_binary_accuracy: 0.9375\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2283 - auc_1: 0.9815 - binary_accuracy: 0.9391 - val_loss: 0.2287 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9381\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2284 - auc_1: 0.9814 - binary_accuracy: 0.9384 - val_loss: 0.2296 - val_auc_1: 0.9810 - val_binary_accuracy: 0.9388\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2279 - auc_1: 0.9815 - binary_accuracy: 0.9391 - val_loss: 0.2299 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9406\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2281 - auc_1: 0.9816 - binary_accuracy: 0.9397 - val_loss: 0.2287 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9378\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2281 - auc_1: 0.9815 - binary_accuracy: 0.9395 - val_loss: 0.2290 - val_auc_1: 0.9814 - val_binary_accuracy: 0.9391\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2279 - auc_1: 0.9817 - binary_accuracy: 0.9400 - val_loss: 0.2291 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9381\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2279 - auc_1: 0.9816 - binary_accuracy: 0.9394 - val_loss: 0.2290 - val_auc_1: 0.9811 - val_binary_accuracy: 0.9391\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2277 - auc_1: 0.9818 - binary_accuracy: 0.9395 - val_loss: 0.2291 - val_auc_1: 0.9814 - val_binary_accuracy: 0.9406\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2277 - auc_1: 0.9818 - binary_accuracy: 0.9391 - val_loss: 0.2289 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9391\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2276 - auc_1: 0.9818 - binary_accuracy: 0.9399 - val_loss: 0.2281 - val_auc_1: 0.9815 - val_binary_accuracy: 0.9384\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2275 - auc_1: 0.9819 - binary_accuracy: 0.9390 - val_loss: 0.2285 - val_auc_1: 0.9816 - val_binary_accuracy: 0.9391\n",
      "Epoch 97/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2272 - auc_1: 0.9819 - binary_accuracy: 0.9405 - val_loss: 0.2289 - val_auc_1: 0.9818 - val_binary_accuracy: 0.9422\n",
      "Epoch 98/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2275 - auc_1: 0.9821 - binary_accuracy: 0.9399 - val_loss: 0.2289 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9400\n",
      "Epoch 99/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2273 - auc_1: 0.9821 - binary_accuracy: 0.9404 - val_loss: 0.2292 - val_auc_1: 0.9813 - val_binary_accuracy: 0.9409\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2270 - auc_1: 0.9820 - binary_accuracy: 0.9406 - val_loss: 0.2290 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9400\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2273 - auc_1: 0.9820 - binary_accuracy: 0.9398 - val_loss: 0.2288 - val_auc_1: 0.9812 - val_binary_accuracy: 0.9409\n",
      "Epoch 102/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2270 - auc_1: 0.9821 - binary_accuracy: 0.9401 - val_loss: 0.2285 - val_auc_1: 0.9816 - val_binary_accuracy: 0.9394\n",
      "Epoch 103/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2272 - auc_1: 0.9821 - binary_accuracy: 0.9402 - val_loss: 0.2295 - val_auc_1: 0.9815 - val_binary_accuracy: 0.9409\n",
      "Epoch 104/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2270 - auc_1: 0.9822 - binary_accuracy: 0.9396 - val_loss: 0.2283 - val_auc_1: 0.9815 - val_binary_accuracy: 0.9409\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2268 - auc_1: 0.9822 - binary_accuracy: 0.9409 - val_loss: 0.2291 - val_auc_1: 0.9817 - val_binary_accuracy: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c621ac520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "200/200 [==============================] - 2s 4ms/step - loss: 0.8446 - AUC: 0.3847 - binary_accuracy: 0.4023 - val_loss: 0.7682 - val_AUC: 0.4060 - val_binary_accuracy: 0.4153\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7407 - AUC: 0.4627 - binary_accuracy: 0.4601 - val_loss: 0.7094 - val_AUC: 0.5541 - val_binary_accuracy: 0.5269\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6771 - AUC: 0.6743 - binary_accuracy: 0.6305 - val_loss: 0.6373 - val_AUC: 0.7702 - val_binary_accuracy: 0.7019\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6171 - AUC: 0.7885 - binary_accuracy: 0.7215 - val_loss: 0.5911 - val_AUC: 0.8178 - val_binary_accuracy: 0.7597\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5829 - AUC: 0.8219 - binary_accuracy: 0.7644 - val_loss: 0.5624 - val_AUC: 0.8438 - val_binary_accuracy: 0.7819\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5583 - AUC: 0.8459 - binary_accuracy: 0.7852 - val_loss: 0.5403 - val_AUC: 0.8633 - val_binary_accuracy: 0.7962\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5392 - AUC: 0.8605 - binary_accuracy: 0.7992 - val_loss: 0.5231 - val_AUC: 0.8743 - val_binary_accuracy: 0.8066\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5247 - AUC: 0.8700 - binary_accuracy: 0.8070 - val_loss: 0.5099 - val_AUC: 0.8809 - val_binary_accuracy: 0.8144\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5139 - AUC: 0.8742 - binary_accuracy: 0.8117 - val_loss: 0.5005 - val_AUC: 0.8847 - val_binary_accuracy: 0.8172\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5060 - AUC: 0.8779 - binary_accuracy: 0.8137 - val_loss: 0.4938 - val_AUC: 0.8864 - val_binary_accuracy: 0.8178\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5004 - AUC: 0.8799 - binary_accuracy: 0.8135 - val_loss: 0.4887 - val_AUC: 0.8882 - val_binary_accuracy: 0.8206\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4963 - AUC: 0.8808 - binary_accuracy: 0.8144 - val_loss: 0.4852 - val_AUC: 0.8893 - val_binary_accuracy: 0.8228\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4934 - AUC: 0.8817 - binary_accuracy: 0.8152 - val_loss: 0.4824 - val_AUC: 0.8901 - val_binary_accuracy: 0.8200\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4911 - AUC: 0.8830 - binary_accuracy: 0.8137 - val_loss: 0.4802 - val_AUC: 0.8906 - val_binary_accuracy: 0.8200\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4893 - AUC: 0.8828 - binary_accuracy: 0.8148 - val_loss: 0.4788 - val_AUC: 0.8908 - val_binary_accuracy: 0.8206\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4879 - AUC: 0.8835 - binary_accuracy: 0.8155 - val_loss: 0.4773 - val_AUC: 0.8914 - val_binary_accuracy: 0.8188\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4868 - AUC: 0.8838 - binary_accuracy: 0.8154 - val_loss: 0.4760 - val_AUC: 0.8918 - val_binary_accuracy: 0.8197\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4859 - AUC: 0.8842 - binary_accuracy: 0.8154 - val_loss: 0.4751 - val_AUC: 0.8919 - val_binary_accuracy: 0.8209\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4851 - AUC: 0.8843 - binary_accuracy: 0.8152 - val_loss: 0.4743 - val_AUC: 0.8922 - val_binary_accuracy: 0.8209\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4844 - AUC: 0.8846 - binary_accuracy: 0.8152 - val_loss: 0.4736 - val_AUC: 0.8924 - val_binary_accuracy: 0.8203\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4838 - AUC: 0.8848 - binary_accuracy: 0.8158 - val_loss: 0.4732 - val_AUC: 0.8927 - val_binary_accuracy: 0.8222\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4834 - AUC: 0.8850 - binary_accuracy: 0.8160 - val_loss: 0.4728 - val_AUC: 0.8926 - val_binary_accuracy: 0.8213\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4829 - AUC: 0.8855 - binary_accuracy: 0.8162 - val_loss: 0.4725 - val_AUC: 0.8926 - val_binary_accuracy: 0.8206\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4824 - AUC: 0.8857 - binary_accuracy: 0.8177 - val_loss: 0.4719 - val_AUC: 0.8931 - val_binary_accuracy: 0.8209\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 3ms/step - loss: 0.4823 - AUC: 0.8856 - binary_accuracy: 0.8160 - val_loss: 0.4715 - val_AUC: 0.8930 - val_binary_accuracy: 0.8222\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4819 - AUC: 0.8856 - binary_accuracy: 0.8170 - val_loss: 0.4713 - val_AUC: 0.8932 - val_binary_accuracy: 0.8216\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4816 - AUC: 0.8860 - binary_accuracy: 0.8169 - val_loss: 0.4709 - val_AUC: 0.8929 - val_binary_accuracy: 0.8225\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4814 - AUC: 0.8861 - binary_accuracy: 0.8168 - val_loss: 0.4704 - val_AUC: 0.8934 - val_binary_accuracy: 0.8225\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4811 - AUC: 0.8862 - binary_accuracy: 0.8172 - val_loss: 0.4704 - val_AUC: 0.8932 - val_binary_accuracy: 0.8238\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4809 - AUC: 0.8864 - binary_accuracy: 0.8172 - val_loss: 0.4702 - val_AUC: 0.8932 - val_binary_accuracy: 0.8231\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4806 - AUC: 0.8864 - binary_accuracy: 0.8185 - val_loss: 0.4702 - val_AUC: 0.8933 - val_binary_accuracy: 0.8241\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4804 - AUC: 0.8866 - binary_accuracy: 0.8170 - val_loss: 0.4701 - val_AUC: 0.8935 - val_binary_accuracy: 0.8250\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4803 - AUC: 0.8869 - binary_accuracy: 0.8169 - val_loss: 0.4700 - val_AUC: 0.8934 - val_binary_accuracy: 0.8225\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4802 - AUC: 0.8868 - binary_accuracy: 0.8168 - val_loss: 0.4702 - val_AUC: 0.8933 - val_binary_accuracy: 0.8231\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4800 - AUC: 0.8869 - binary_accuracy: 0.8158 - val_loss: 0.4697 - val_AUC: 0.8935 - val_binary_accuracy: 0.8234\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4799 - AUC: 0.8870 - binary_accuracy: 0.8172 - val_loss: 0.4695 - val_AUC: 0.8937 - val_binary_accuracy: 0.8269\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4797 - AUC: 0.8872 - binary_accuracy: 0.8170 - val_loss: 0.4692 - val_AUC: 0.8939 - val_binary_accuracy: 0.8244\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4796 - AUC: 0.8873 - binary_accuracy: 0.8167 - val_loss: 0.4695 - val_AUC: 0.8938 - val_binary_accuracy: 0.8234\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4793 - AUC: 0.8875 - binary_accuracy: 0.8166 - val_loss: 0.4692 - val_AUC: 0.8938 - val_binary_accuracy: 0.8291\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4793 - AUC: 0.8875 - binary_accuracy: 0.8180 - val_loss: 0.4691 - val_AUC: 0.8941 - val_binary_accuracy: 0.8263\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4792 - AUC: 0.8877 - binary_accuracy: 0.8191 - val_loss: 0.4691 - val_AUC: 0.8941 - val_binary_accuracy: 0.8247\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4790 - AUC: 0.8876 - binary_accuracy: 0.8174 - val_loss: 0.4689 - val_AUC: 0.8944 - val_binary_accuracy: 0.8269\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4790 - AUC: 0.8880 - binary_accuracy: 0.8177 - val_loss: 0.4690 - val_AUC: 0.8941 - val_binary_accuracy: 0.8241\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4788 - AUC: 0.8878 - binary_accuracy: 0.8177 - val_loss: 0.4688 - val_AUC: 0.8943 - val_binary_accuracy: 0.8259\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4787 - AUC: 0.8879 - binary_accuracy: 0.8179 - val_loss: 0.4688 - val_AUC: 0.8942 - val_binary_accuracy: 0.8259\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4786 - AUC: 0.8880 - binary_accuracy: 0.8175 - val_loss: 0.4688 - val_AUC: 0.8945 - val_binary_accuracy: 0.8269\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4785 - AUC: 0.8882 - binary_accuracy: 0.8181 - val_loss: 0.4685 - val_AUC: 0.8945 - val_binary_accuracy: 0.8272\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4783 - AUC: 0.8883 - binary_accuracy: 0.8183 - val_loss: 0.4690 - val_AUC: 0.8943 - val_binary_accuracy: 0.8247\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4784 - AUC: 0.8882 - binary_accuracy: 0.8171 - val_loss: 0.4686 - val_AUC: 0.8943 - val_binary_accuracy: 0.8294\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4783 - AUC: 0.8884 - binary_accuracy: 0.8178 - val_loss: 0.4683 - val_AUC: 0.8946 - val_binary_accuracy: 0.8278\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4782 - AUC: 0.8883 - binary_accuracy: 0.8188 - val_loss: 0.4684 - val_AUC: 0.8946 - val_binary_accuracy: 0.8241\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4781 - AUC: 0.8886 - binary_accuracy: 0.8183 - val_loss: 0.4685 - val_AUC: 0.8945 - val_binary_accuracy: 0.8259\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4780 - AUC: 0.8885 - binary_accuracy: 0.8185 - val_loss: 0.4685 - val_AUC: 0.8947 - val_binary_accuracy: 0.8253\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4781 - AUC: 0.8885 - binary_accuracy: 0.8182 - val_loss: 0.4683 - val_AUC: 0.8947 - val_binary_accuracy: 0.8272\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4779 - AUC: 0.8888 - binary_accuracy: 0.8188 - val_loss: 0.4684 - val_AUC: 0.8946 - val_binary_accuracy: 0.8272\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4779 - AUC: 0.8887 - binary_accuracy: 0.8193 - val_loss: 0.4682 - val_AUC: 0.8948 - val_binary_accuracy: 0.8263\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4777 - AUC: 0.8888 - binary_accuracy: 0.8183 - val_loss: 0.4680 - val_AUC: 0.8946 - val_binary_accuracy: 0.8272\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4777 - AUC: 0.8887 - binary_accuracy: 0.8181 - val_loss: 0.4681 - val_AUC: 0.8950 - val_binary_accuracy: 0.8269\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4776 - AUC: 0.8888 - binary_accuracy: 0.8178 - val_loss: 0.4684 - val_AUC: 0.8951 - val_binary_accuracy: 0.8297\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4776 - AUC: 0.8890 - binary_accuracy: 0.8186 - val_loss: 0.4678 - val_AUC: 0.8950 - val_binary_accuracy: 0.8278\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4776 - AUC: 0.8889 - binary_accuracy: 0.8186 - val_loss: 0.4678 - val_AUC: 0.8952 - val_binary_accuracy: 0.8272\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4776 - AUC: 0.8890 - binary_accuracy: 0.8187 - val_loss: 0.4679 - val_AUC: 0.8950 - val_binary_accuracy: 0.8300\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4774 - AUC: 0.8891 - binary_accuracy: 0.8180 - val_loss: 0.4678 - val_AUC: 0.8953 - val_binary_accuracy: 0.8288\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4775 - AUC: 0.8891 - binary_accuracy: 0.8180 - val_loss: 0.4677 - val_AUC: 0.8950 - val_binary_accuracy: 0.8278\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4773 - AUC: 0.8891 - binary_accuracy: 0.8184 - val_loss: 0.4681 - val_AUC: 0.8951 - val_binary_accuracy: 0.8234\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4773 - AUC: 0.8892 - binary_accuracy: 0.8183 - val_loss: 0.4678 - val_AUC: 0.8953 - val_binary_accuracy: 0.8281\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4773 - AUC: 0.8891 - binary_accuracy: 0.8187 - val_loss: 0.4676 - val_AUC: 0.8953 - val_binary_accuracy: 0.8275\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4772 - AUC: 0.8893 - binary_accuracy: 0.8177 - val_loss: 0.4678 - val_AUC: 0.8953 - val_binary_accuracy: 0.8272\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4771 - AUC: 0.8895 - binary_accuracy: 0.8183 - val_loss: 0.4679 - val_AUC: 0.8951 - val_binary_accuracy: 0.8288\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4771 - AUC: 0.8893 - binary_accuracy: 0.8188 - val_loss: 0.4679 - val_AUC: 0.8952 - val_binary_accuracy: 0.8256\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4771 - AUC: 0.8893 - binary_accuracy: 0.8187 - val_loss: 0.4676 - val_AUC: 0.8955 - val_binary_accuracy: 0.8297\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4770 - AUC: 0.8893 - binary_accuracy: 0.8187 - val_loss: 0.4676 - val_AUC: 0.8955 - val_binary_accuracy: 0.8253\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4770 - AUC: 0.8895 - binary_accuracy: 0.8195 - val_loss: 0.4679 - val_AUC: 0.8954 - val_binary_accuracy: 0.8278\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4770 - AUC: 0.8898 - binary_accuracy: 0.8187 - val_loss: 0.4676 - val_AUC: 0.8956 - val_binary_accuracy: 0.8263\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4769 - AUC: 0.8896 - binary_accuracy: 0.8179 - val_loss: 0.4674 - val_AUC: 0.8957 - val_binary_accuracy: 0.8291\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4768 - AUC: 0.8897 - binary_accuracy: 0.8185 - val_loss: 0.4677 - val_AUC: 0.8956 - val_binary_accuracy: 0.8288\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4769 - AUC: 0.8895 - binary_accuracy: 0.8191 - val_loss: 0.4677 - val_AUC: 0.8956 - val_binary_accuracy: 0.8288\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4770 - AUC: 0.8894 - binary_accuracy: 0.8188 - val_loss: 0.4677 - val_AUC: 0.8956 - val_binary_accuracy: 0.8259\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4768 - AUC: 0.8896 - binary_accuracy: 0.8185 - val_loss: 0.4679 - val_AUC: 0.8956 - val_binary_accuracy: 0.8259\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4768 - AUC: 0.8899 - binary_accuracy: 0.8184 - val_loss: 0.4673 - val_AUC: 0.8959 - val_binary_accuracy: 0.8272\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4767 - AUC: 0.8898 - binary_accuracy: 0.8193 - val_loss: 0.4675 - val_AUC: 0.8956 - val_binary_accuracy: 0.8247\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4766 - AUC: 0.8899 - binary_accuracy: 0.8193 - val_loss: 0.4676 - val_AUC: 0.8954 - val_binary_accuracy: 0.8266\n",
      "Epoch 83/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4766 - AUC: 0.8897 - binary_accuracy: 0.8188 - val_loss: 0.4673 - val_AUC: 0.8958 - val_binary_accuracy: 0.8269\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4765 - AUC: 0.8899 - binary_accuracy: 0.8184 - val_loss: 0.4677 - val_AUC: 0.8958 - val_binary_accuracy: 0.8278\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4767 - AUC: 0.8897 - binary_accuracy: 0.8191 - val_loss: 0.4674 - val_AUC: 0.8960 - val_binary_accuracy: 0.8259\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4765 - AUC: 0.8900 - binary_accuracy: 0.8195 - val_loss: 0.4675 - val_AUC: 0.8961 - val_binary_accuracy: 0.8272\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4765 - AUC: 0.8900 - binary_accuracy: 0.8196 - val_loss: 0.4673 - val_AUC: 0.8961 - val_binary_accuracy: 0.8259\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4765 - AUC: 0.8902 - binary_accuracy: 0.8192 - val_loss: 0.4674 - val_AUC: 0.8957 - val_binary_accuracy: 0.8241\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4764 - AUC: 0.8900 - binary_accuracy: 0.8198 - val_loss: 0.4677 - val_AUC: 0.8958 - val_binary_accuracy: 0.8241\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4764 - AUC: 0.8899 - binary_accuracy: 0.8188 - val_loss: 0.4672 - val_AUC: 0.8961 - val_binary_accuracy: 0.8256\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8188 - val_loss: 0.4673 - val_AUC: 0.8959 - val_binary_accuracy: 0.8256\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8202 - val_loss: 0.4675 - val_AUC: 0.8961 - val_binary_accuracy: 0.8241\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4764 - AUC: 0.8901 - binary_accuracy: 0.8193 - val_loss: 0.4670 - val_AUC: 0.8962 - val_binary_accuracy: 0.8253\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4762 - AUC: 0.8903 - binary_accuracy: 0.8183 - val_loss: 0.4673 - val_AUC: 0.8963 - val_binary_accuracy: 0.8281\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4763 - AUC: 0.8902 - binary_accuracy: 0.8188 - val_loss: 0.4670 - val_AUC: 0.8962 - val_binary_accuracy: 0.8253\n",
      "Epoch 96/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4762 - AUC: 0.8903 - binary_accuracy: 0.8212 - val_loss: 0.4674 - val_AUC: 0.8959 - val_binary_accuracy: 0.8231\n",
      "Epoch 97/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4762 - AUC: 0.8904 - binary_accuracy: 0.8196 - val_loss: 0.4668 - val_AUC: 0.8962 - val_binary_accuracy: 0.8266\n",
      "Epoch 98/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4761 - AUC: 0.8902 - binary_accuracy: 0.8201 - val_loss: 0.4673 - val_AUC: 0.8962 - val_binary_accuracy: 0.8241\n",
      "Epoch 99/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4763 - AUC: 0.8903 - binary_accuracy: 0.8191 - val_loss: 0.4671 - val_AUC: 0.8962 - val_binary_accuracy: 0.8256\n",
      "Epoch 100/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4762 - AUC: 0.8903 - binary_accuracy: 0.8190 - val_loss: 0.4668 - val_AUC: 0.8965 - val_binary_accuracy: 0.8253\n",
      "Epoch 101/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4761 - AUC: 0.8901 - binary_accuracy: 0.8190 - val_loss: 0.4674 - val_AUC: 0.8963 - val_binary_accuracy: 0.8234\n",
      "Epoch 102/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4762 - AUC: 0.8904 - binary_accuracy: 0.8184 - val_loss: 0.4668 - val_AUC: 0.8964 - val_binary_accuracy: 0.8259\n",
      "Epoch 103/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8906 - binary_accuracy: 0.8211 - val_loss: 0.4673 - val_AUC: 0.8962 - val_binary_accuracy: 0.8231\n",
      "Epoch 104/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8904 - binary_accuracy: 0.8185 - val_loss: 0.4668 - val_AUC: 0.8964 - val_binary_accuracy: 0.8259\n",
      "Epoch 105/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8904 - binary_accuracy: 0.8186 - val_loss: 0.4669 - val_AUC: 0.8962 - val_binary_accuracy: 0.8269\n",
      "Epoch 106/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8905 - binary_accuracy: 0.8200 - val_loss: 0.4666 - val_AUC: 0.8963 - val_binary_accuracy: 0.8247\n",
      "Epoch 107/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8904 - binary_accuracy: 0.8184 - val_loss: 0.4667 - val_AUC: 0.8962 - val_binary_accuracy: 0.8266\n",
      "Epoch 108/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8904 - binary_accuracy: 0.8205 - val_loss: 0.4667 - val_AUC: 0.8964 - val_binary_accuracy: 0.8259\n",
      "Epoch 109/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4759 - AUC: 0.8904 - binary_accuracy: 0.8186 - val_loss: 0.4668 - val_AUC: 0.8967 - val_binary_accuracy: 0.8269\n",
      "Epoch 110/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8905 - binary_accuracy: 0.8198 - val_loss: 0.4668 - val_AUC: 0.8962 - val_binary_accuracy: 0.8256\n",
      "Epoch 111/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8905 - binary_accuracy: 0.8198 - val_loss: 0.4666 - val_AUC: 0.8966 - val_binary_accuracy: 0.8263\n",
      "Epoch 112/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4760 - AUC: 0.8905 - binary_accuracy: 0.8195 - val_loss: 0.4667 - val_AUC: 0.8963 - val_binary_accuracy: 0.8259\n",
      "Epoch 113/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4758 - AUC: 0.8906 - binary_accuracy: 0.8204 - val_loss: 0.4666 - val_AUC: 0.8966 - val_binary_accuracy: 0.8231\n",
      "Epoch 114/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4758 - AUC: 0.8905 - binary_accuracy: 0.8188 - val_loss: 0.4667 - val_AUC: 0.8965 - val_binary_accuracy: 0.8247\n",
      "Epoch 115/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4759 - AUC: 0.8905 - binary_accuracy: 0.8214 - val_loss: 0.4665 - val_AUC: 0.8966 - val_binary_accuracy: 0.8247\n",
      "Epoch 116/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4759 - AUC: 0.8906 - binary_accuracy: 0.8191 - val_loss: 0.4664 - val_AUC: 0.8966 - val_binary_accuracy: 0.8256\n",
      "Epoch 117/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4758 - AUC: 0.8906 - binary_accuracy: 0.8195 - val_loss: 0.4669 - val_AUC: 0.8963 - val_binary_accuracy: 0.8266\n",
      "Epoch 118/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4758 - AUC: 0.8907 - binary_accuracy: 0.8198 - val_loss: 0.4667 - val_AUC: 0.8963 - val_binary_accuracy: 0.8272\n",
      "Epoch 119/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4758 - AUC: 0.8904 - binary_accuracy: 0.8194 - val_loss: 0.4669 - val_AUC: 0.8965 - val_binary_accuracy: 0.8231\n",
      "Epoch 1/200\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7092 - AUC: 0.6960 - binary_accuracy: 0.6484 - val_loss: 0.6504 - val_AUC: 0.7860 - val_binary_accuracy: 0.7287\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6123 - AUC: 0.8174 - binary_accuracy: 0.7521 - val_loss: 0.5655 - val_AUC: 0.8468 - val_binary_accuracy: 0.7931\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5425 - AUC: 0.8561 - binary_accuracy: 0.7898 - val_loss: 0.5070 - val_AUC: 0.8782 - val_binary_accuracy: 0.8109\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5003 - AUC: 0.8810 - binary_accuracy: 0.8007 - val_loss: 0.4762 - val_AUC: 0.8981 - val_binary_accuracy: 0.8184\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4772 - AUC: 0.8965 - binary_accuracy: 0.8031 - val_loss: 0.4583 - val_AUC: 0.9108 - val_binary_accuracy: 0.8203\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4628 - AUC: 0.9075 - binary_accuracy: 0.8070 - val_loss: 0.4480 - val_AUC: 0.9181 - val_binary_accuracy: 0.8206\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4530 - AUC: 0.9151 - binary_accuracy: 0.8097 - val_loss: 0.4410 - val_AUC: 0.9248 - val_binary_accuracy: 0.8213\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4457 - AUC: 0.9209 - binary_accuracy: 0.8125 - val_loss: 0.4363 - val_AUC: 0.9289 - val_binary_accuracy: 0.8234\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4405 - AUC: 0.9251 - binary_accuracy: 0.8138 - val_loss: 0.4322 - val_AUC: 0.9314 - val_binary_accuracy: 0.8281\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4366 - AUC: 0.9289 - binary_accuracy: 0.8187 - val_loss: 0.4297 - val_AUC: 0.9335 - val_binary_accuracy: 0.8294\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4335 - AUC: 0.9310 - binary_accuracy: 0.8225 - val_loss: 0.4274 - val_AUC: 0.9358 - val_binary_accuracy: 0.8309\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4304 - AUC: 0.9335 - binary_accuracy: 0.8329 - val_loss: 0.4247 - val_AUC: 0.9381 - val_binary_accuracy: 0.8553\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4255 - AUC: 0.9369 - binary_accuracy: 0.8637 - val_loss: 0.4201 - val_AUC: 0.9414 - val_binary_accuracy: 0.8766\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4213 - AUC: 0.9402 - binary_accuracy: 0.8740 - val_loss: 0.4168 - val_AUC: 0.9439 - val_binary_accuracy: 0.8813\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4170 - AUC: 0.9437 - binary_accuracy: 0.8790 - val_loss: 0.4137 - val_AUC: 0.9456 - val_binary_accuracy: 0.8772\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4141 - AUC: 0.9453 - binary_accuracy: 0.8799 - val_loss: 0.4127 - val_AUC: 0.9473 - val_binary_accuracy: 0.8816\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4127 - AUC: 0.9470 - binary_accuracy: 0.8816 - val_loss: 0.4113 - val_AUC: 0.9477 - val_binary_accuracy: 0.8834\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4117 - AUC: 0.9478 - binary_accuracy: 0.8835 - val_loss: 0.4107 - val_AUC: 0.9481 - val_binary_accuracy: 0.8809\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4112 - AUC: 0.9480 - binary_accuracy: 0.8830 - val_loss: 0.4111 - val_AUC: 0.9486 - val_binary_accuracy: 0.8794\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4105 - AUC: 0.9488 - binary_accuracy: 0.8840 - val_loss: 0.4103 - val_AUC: 0.9491 - val_binary_accuracy: 0.8813\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4100 - AUC: 0.9493 - binary_accuracy: 0.8838 - val_loss: 0.4096 - val_AUC: 0.9495 - val_binary_accuracy: 0.8859\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4097 - AUC: 0.9494 - binary_accuracy: 0.8845 - val_loss: 0.4097 - val_AUC: 0.9498 - val_binary_accuracy: 0.8831\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4090 - AUC: 0.9500 - binary_accuracy: 0.8842 - val_loss: 0.4088 - val_AUC: 0.9496 - val_binary_accuracy: 0.8859\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4085 - AUC: 0.9498 - binary_accuracy: 0.8849 - val_loss: 0.4091 - val_AUC: 0.9499 - val_binary_accuracy: 0.8834\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4082 - AUC: 0.9503 - binary_accuracy: 0.8842 - val_loss: 0.4082 - val_AUC: 0.9506 - val_binary_accuracy: 0.8878\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4074 - AUC: 0.9507 - binary_accuracy: 0.8851 - val_loss: 0.4078 - val_AUC: 0.9508 - val_binary_accuracy: 0.8863\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4070 - AUC: 0.9509 - binary_accuracy: 0.8859 - val_loss: 0.4071 - val_AUC: 0.9515 - val_binary_accuracy: 0.8875\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4060 - AUC: 0.9516 - binary_accuracy: 0.8864 - val_loss: 0.4059 - val_AUC: 0.9516 - val_binary_accuracy: 0.8884\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4054 - AUC: 0.9519 - binary_accuracy: 0.8866 - val_loss: 0.4051 - val_AUC: 0.9520 - val_binary_accuracy: 0.8863\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4045 - AUC: 0.9524 - binary_accuracy: 0.8868 - val_loss: 0.4042 - val_AUC: 0.9524 - val_binary_accuracy: 0.8869\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4036 - AUC: 0.9527 - binary_accuracy: 0.8886 - val_loss: 0.4042 - val_AUC: 0.9529 - val_binary_accuracy: 0.8863\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4031 - AUC: 0.9532 - binary_accuracy: 0.8886 - val_loss: 0.4032 - val_AUC: 0.9530 - val_binary_accuracy: 0.8875\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4026 - AUC: 0.9534 - binary_accuracy: 0.8884 - val_loss: 0.4029 - val_AUC: 0.9535 - val_binary_accuracy: 0.8872\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4021 - AUC: 0.9538 - binary_accuracy: 0.8891 - val_loss: 0.4026 - val_AUC: 0.9534 - val_binary_accuracy: 0.8872\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4018 - AUC: 0.9538 - binary_accuracy: 0.8894 - val_loss: 0.4017 - val_AUC: 0.9540 - val_binary_accuracy: 0.8894\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4014 - AUC: 0.9541 - binary_accuracy: 0.8888 - val_loss: 0.4013 - val_AUC: 0.9542 - val_binary_accuracy: 0.8875\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4011 - AUC: 0.9543 - binary_accuracy: 0.8886 - val_loss: 0.4010 - val_AUC: 0.9542 - val_binary_accuracy: 0.8878\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4008 - AUC: 0.9544 - binary_accuracy: 0.8899 - val_loss: 0.4009 - val_AUC: 0.9544 - val_binary_accuracy: 0.8878\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4007 - AUC: 0.9546 - binary_accuracy: 0.8886 - val_loss: 0.4007 - val_AUC: 0.9545 - val_binary_accuracy: 0.8888\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4005 - AUC: 0.9545 - binary_accuracy: 0.8888 - val_loss: 0.4006 - val_AUC: 0.9550 - val_binary_accuracy: 0.8894\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4004 - AUC: 0.9548 - binary_accuracy: 0.8900 - val_loss: 0.4002 - val_AUC: 0.9547 - val_binary_accuracy: 0.8897\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4002 - AUC: 0.9545 - binary_accuracy: 0.8897 - val_loss: 0.4004 - val_AUC: 0.9548 - val_binary_accuracy: 0.8888\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4002 - AUC: 0.9548 - binary_accuracy: 0.8903 - val_loss: 0.4001 - val_AUC: 0.9550 - val_binary_accuracy: 0.8891\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4000 - AUC: 0.9548 - binary_accuracy: 0.8892 - val_loss: 0.4000 - val_AUC: 0.9550 - val_binary_accuracy: 0.8897\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3998 - AUC: 0.9548 - binary_accuracy: 0.8898 - val_loss: 0.3998 - val_AUC: 0.9552 - val_binary_accuracy: 0.8903\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3999 - AUC: 0.9550 - binary_accuracy: 0.8899 - val_loss: 0.3998 - val_AUC: 0.9552 - val_binary_accuracy: 0.8891\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3997 - AUC: 0.9549 - binary_accuracy: 0.8899 - val_loss: 0.3997 - val_AUC: 0.9549 - val_binary_accuracy: 0.8884\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3995 - AUC: 0.9554 - binary_accuracy: 0.8909 - val_loss: 0.3995 - val_AUC: 0.9548 - val_binary_accuracy: 0.8922\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3997 - AUC: 0.9548 - binary_accuracy: 0.8902 - val_loss: 0.3991 - val_AUC: 0.9552 - val_binary_accuracy: 0.8884\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3996 - AUC: 0.9551 - binary_accuracy: 0.8905 - val_loss: 0.3996 - val_AUC: 0.9549 - val_binary_accuracy: 0.8888\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3995 - AUC: 0.9549 - binary_accuracy: 0.8904 - val_loss: 0.3993 - val_AUC: 0.9550 - val_binary_accuracy: 0.8900\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3996 - AUC: 0.9551 - binary_accuracy: 0.8901 - val_loss: 0.3992 - val_AUC: 0.9552 - val_binary_accuracy: 0.8891\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3994 - AUC: 0.9550 - binary_accuracy: 0.8896 - val_loss: 0.3991 - val_AUC: 0.9550 - val_binary_accuracy: 0.8894\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3994 - AUC: 0.9552 - binary_accuracy: 0.8893 - val_loss: 0.3992 - val_AUC: 0.9549 - val_binary_accuracy: 0.8903\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3994 - AUC: 0.9551 - binary_accuracy: 0.8897 - val_loss: 0.3991 - val_AUC: 0.9551 - val_binary_accuracy: 0.8891\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9553 - binary_accuracy: 0.8904 - val_loss: 0.3988 - val_AUC: 0.9549 - val_binary_accuracy: 0.8891\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3993 - AUC: 0.9550 - binary_accuracy: 0.8893 - val_loss: 0.3994 - val_AUC: 0.9549 - val_binary_accuracy: 0.8881\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3994 - AUC: 0.9551 - binary_accuracy: 0.8892 - val_loss: 0.3990 - val_AUC: 0.9550 - val_binary_accuracy: 0.8903\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.3994 - AUC: 0.9550 - binary_accuracy: 0.8908 - val_loss: 0.3992 - val_AUC: 0.9552 - val_binary_accuracy: 0.8900\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9551 - binary_accuracy: 0.8903 - val_loss: 0.3989 - val_AUC: 0.9553 - val_binary_accuracy: 0.8906\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9551 - binary_accuracy: 0.8893 - val_loss: 0.3990 - val_AUC: 0.9552 - val_binary_accuracy: 0.8906\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9551 - binary_accuracy: 0.8890 - val_loss: 0.3990 - val_AUC: 0.9553 - val_binary_accuracy: 0.8897\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9553 - binary_accuracy: 0.8905 - val_loss: 0.3990 - val_AUC: 0.9549 - val_binary_accuracy: 0.8897\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9552 - binary_accuracy: 0.8894 - val_loss: 0.3990 - val_AUC: 0.9554 - val_binary_accuracy: 0.8909\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9553 - binary_accuracy: 0.8901 - val_loss: 0.3987 - val_AUC: 0.9550 - val_binary_accuracy: 0.8906\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9552 - binary_accuracy: 0.8900 - val_loss: 0.3990 - val_AUC: 0.9551 - val_binary_accuracy: 0.8903\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9551 - binary_accuracy: 0.8902 - val_loss: 0.3987 - val_AUC: 0.9551 - val_binary_accuracy: 0.8919\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9550 - binary_accuracy: 0.8901 - val_loss: 0.3988 - val_AUC: 0.9550 - val_binary_accuracy: 0.8913\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9553 - binary_accuracy: 0.8890 - val_loss: 0.3991 - val_AUC: 0.9550 - val_binary_accuracy: 0.8891\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3991 - AUC: 0.9552 - binary_accuracy: 0.8895 - val_loss: 0.3989 - val_AUC: 0.9550 - val_binary_accuracy: 0.8900\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3992 - AUC: 0.9553 - binary_accuracy: 0.8895 - val_loss: 0.3987 - val_AUC: 0.9550 - val_binary_accuracy: 0.8891\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3991 - AUC: 0.9553 - binary_accuracy: 0.8896 - val_loss: 0.3991 - val_AUC: 0.9549 - val_binary_accuracy: 0.8922\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9552 - binary_accuracy: 0.8895 - val_loss: 0.3988 - val_AUC: 0.9547 - val_binary_accuracy: 0.8903\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3993 - AUC: 0.9551 - binary_accuracy: 0.8895 - val_loss: 0.3990 - val_AUC: 0.9550 - val_binary_accuracy: 0.8903\n",
      "Epoch 1/200\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6631 - AUC: 0.7132 - binary_accuracy: 0.6673 - val_loss: 0.6080 - val_AUC: 0.7886 - val_binary_accuracy: 0.7297\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5849 - AUC: 0.8155 - binary_accuracy: 0.7485 - val_loss: 0.5544 - val_AUC: 0.8431 - val_binary_accuracy: 0.7791\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5496 - AUC: 0.8422 - binary_accuracy: 0.7753 - val_loss: 0.5307 - val_AUC: 0.8544 - val_binary_accuracy: 0.7937\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5327 - AUC: 0.8501 - binary_accuracy: 0.7834 - val_loss: 0.5173 - val_AUC: 0.8608 - val_binary_accuracy: 0.7978\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5227 - AUC: 0.8553 - binary_accuracy: 0.7869 - val_loss: 0.5087 - val_AUC: 0.8652 - val_binary_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5160 - AUC: 0.8590 - binary_accuracy: 0.7887 - val_loss: 0.5027 - val_AUC: 0.8690 - val_binary_accuracy: 0.8028\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5110 - AUC: 0.8634 - binary_accuracy: 0.7909 - val_loss: 0.4980 - val_AUC: 0.8722 - val_binary_accuracy: 0.8034\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5069 - AUC: 0.8651 - binary_accuracy: 0.7922 - val_loss: 0.4942 - val_AUC: 0.8761 - val_binary_accuracy: 0.8022\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5035 - AUC: 0.8690 - binary_accuracy: 0.7925 - val_loss: 0.4911 - val_AUC: 0.8771 - val_binary_accuracy: 0.8066\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5005 - AUC: 0.8702 - binary_accuracy: 0.7927 - val_loss: 0.4884 - val_AUC: 0.8802 - val_binary_accuracy: 0.8050\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4981 - AUC: 0.8724 - binary_accuracy: 0.7940 - val_loss: 0.4864 - val_AUC: 0.8816 - val_binary_accuracy: 0.8069\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4960 - AUC: 0.8738 - binary_accuracy: 0.7936 - val_loss: 0.4846 - val_AUC: 0.8830 - val_binary_accuracy: 0.8087\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4943 - AUC: 0.8750 - binary_accuracy: 0.7926 - val_loss: 0.4832 - val_AUC: 0.8852 - val_binary_accuracy: 0.8094\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4930 - AUC: 0.8762 - binary_accuracy: 0.7931 - val_loss: 0.4823 - val_AUC: 0.8857 - val_binary_accuracy: 0.8078\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4921 - AUC: 0.8770 - binary_accuracy: 0.7901 - val_loss: 0.4814 - val_AUC: 0.8869 - val_binary_accuracy: 0.8091\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4914 - AUC: 0.8775 - binary_accuracy: 0.7898 - val_loss: 0.4809 - val_AUC: 0.8873 - val_binary_accuracy: 0.8109\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4908 - AUC: 0.8782 - binary_accuracy: 0.7909 - val_loss: 0.4807 - val_AUC: 0.8875 - val_binary_accuracy: 0.8128\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4904 - AUC: 0.8785 - binary_accuracy: 0.7909 - val_loss: 0.4805 - val_AUC: 0.8878 - val_binary_accuracy: 0.8112\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4900 - AUC: 0.8788 - binary_accuracy: 0.7909 - val_loss: 0.4800 - val_AUC: 0.8882 - val_binary_accuracy: 0.8116\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4898 - AUC: 0.8791 - binary_accuracy: 0.7921 - val_loss: 0.4799 - val_AUC: 0.8889 - val_binary_accuracy: 0.8106\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4896 - AUC: 0.8795 - binary_accuracy: 0.7912 - val_loss: 0.4798 - val_AUC: 0.8891 - val_binary_accuracy: 0.8106\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4895 - AUC: 0.8799 - binary_accuracy: 0.7923 - val_loss: 0.4795 - val_AUC: 0.8887 - val_binary_accuracy: 0.8106\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4894 - AUC: 0.8796 - binary_accuracy: 0.7923 - val_loss: 0.4797 - val_AUC: 0.8890 - val_binary_accuracy: 0.8106\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4893 - AUC: 0.8800 - binary_accuracy: 0.7935 - val_loss: 0.4794 - val_AUC: 0.8889 - val_binary_accuracy: 0.8106\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4893 - AUC: 0.8800 - binary_accuracy: 0.7929 - val_loss: 0.4795 - val_AUC: 0.8889 - val_binary_accuracy: 0.8094\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4892 - AUC: 0.8802 - binary_accuracy: 0.7936 - val_loss: 0.4797 - val_AUC: 0.8888 - val_binary_accuracy: 0.8106\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4892 - AUC: 0.8801 - binary_accuracy: 0.7935 - val_loss: 0.4796 - val_AUC: 0.8892 - val_binary_accuracy: 0.8112\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4891 - AUC: 0.8802 - binary_accuracy: 0.7941 - val_loss: 0.4794 - val_AUC: 0.8892 - val_binary_accuracy: 0.8100\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4891 - AUC: 0.8800 - binary_accuracy: 0.7936 - val_loss: 0.4795 - val_AUC: 0.8902 - val_binary_accuracy: 0.8109\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4891 - AUC: 0.8804 - binary_accuracy: 0.7952 - val_loss: 0.4795 - val_AUC: 0.8903 - val_binary_accuracy: 0.8128\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4891 - AUC: 0.8806 - binary_accuracy: 0.7934 - val_loss: 0.4795 - val_AUC: 0.8895 - val_binary_accuracy: 0.8112\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4891 - AUC: 0.8806 - binary_accuracy: 0.7939 - val_loss: 0.4796 - val_AUC: 0.8894 - val_binary_accuracy: 0.8103\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4890 - AUC: 0.8802 - binary_accuracy: 0.7948 - val_loss: 0.4795 - val_AUC: 0.8903 - val_binary_accuracy: 0.8116\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4890 - AUC: 0.8807 - binary_accuracy: 0.7944 - val_loss: 0.4795 - val_AUC: 0.8903 - val_binary_accuracy: 0.8112\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4891 - AUC: 0.8808 - binary_accuracy: 0.7933 - val_loss: 0.4797 - val_AUC: 0.8901 - val_binary_accuracy: 0.8097\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4891 - AUC: 0.8806 - binary_accuracy: 0.7953 - val_loss: 0.4795 - val_AUC: 0.8899 - val_binary_accuracy: 0.8119\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4890 - AUC: 0.8809 - binary_accuracy: 0.7936 - val_loss: 0.4796 - val_AUC: 0.8899 - val_binary_accuracy: 0.8106\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4889 - AUC: 0.8807 - binary_accuracy: 0.7942 - val_loss: 0.4796 - val_AUC: 0.8903 - val_binary_accuracy: 0.8106\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4890 - AUC: 0.8805 - binary_accuracy: 0.7955 - val_loss: 0.4797 - val_AUC: 0.8902 - val_binary_accuracy: 0.8112\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4890 - AUC: 0.8809 - binary_accuracy: 0.7955 - val_loss: 0.4795 - val_AUC: 0.8903 - val_binary_accuracy: 0.8116\n",
      "Epoch 1/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7840 - AUC: 0.6394 - binary_accuracy: 0.6299 - val_loss: 0.6554 - val_AUC: 0.7755 - val_binary_accuracy: 0.7256\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6125 - AUC: 0.8108 - binary_accuracy: 0.7563 - val_loss: 0.5607 - val_AUC: 0.8500 - val_binary_accuracy: 0.7944\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5522 - AUC: 0.8522 - binary_accuracy: 0.7806 - val_loss: 0.5199 - val_AUC: 0.8730 - val_binary_accuracy: 0.8062\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.5203 - AUC: 0.8708 - binary_accuracy: 0.7898 - val_loss: 0.4964 - val_AUC: 0.8869 - val_binary_accuracy: 0.8128\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5010 - AUC: 0.8822 - binary_accuracy: 0.7956 - val_loss: 0.4827 - val_AUC: 0.8962 - val_binary_accuracy: 0.8156\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4902 - AUC: 0.8886 - binary_accuracy: 0.7993 - val_loss: 0.4749 - val_AUC: 0.9010 - val_binary_accuracy: 0.8172\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 1s 2ms/step - loss: 0.4837 - AUC: 0.8923 - binary_accuracy: 0.8023 - val_loss: 0.4701 - val_AUC: 0.9041 - val_binary_accuracy: 0.8206\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4794 - AUC: 0.8955 - binary_accuracy: 0.8073 - val_loss: 0.4662 - val_AUC: 0.9070 - val_binary_accuracy: 0.8216\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4756 - AUC: 0.8985 - binary_accuracy: 0.8123 - val_loss: 0.4625 - val_AUC: 0.9098 - val_binary_accuracy: 0.8266\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4720 - AUC: 0.9020 - binary_accuracy: 0.8179 - val_loss: 0.4594 - val_AUC: 0.9121 - val_binary_accuracy: 0.8338\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4688 - AUC: 0.9052 - binary_accuracy: 0.8220 - val_loss: 0.4573 - val_AUC: 0.9147 - val_binary_accuracy: 0.8375\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4663 - AUC: 0.9075 - binary_accuracy: 0.8234 - val_loss: 0.4556 - val_AUC: 0.9174 - val_binary_accuracy: 0.8409\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4643 - AUC: 0.9103 - binary_accuracy: 0.8255 - val_loss: 0.4538 - val_AUC: 0.9197 - val_binary_accuracy: 0.8456\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4626 - AUC: 0.9125 - binary_accuracy: 0.8297 - val_loss: 0.4532 - val_AUC: 0.9216 - val_binary_accuracy: 0.8466\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4614 - AUC: 0.9147 - binary_accuracy: 0.8312 - val_loss: 0.4521 - val_AUC: 0.9226 - val_binary_accuracy: 0.8500\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4604 - AUC: 0.9162 - binary_accuracy: 0.8323 - val_loss: 0.4512 - val_AUC: 0.9238 - val_binary_accuracy: 0.8500\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4595 - AUC: 0.9173 - binary_accuracy: 0.8356 - val_loss: 0.4509 - val_AUC: 0.9253 - val_binary_accuracy: 0.8525\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4587 - AUC: 0.9191 - binary_accuracy: 0.8354 - val_loss: 0.4499 - val_AUC: 0.9258 - val_binary_accuracy: 0.8550\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4582 - AUC: 0.9197 - binary_accuracy: 0.8384 - val_loss: 0.4499 - val_AUC: 0.9272 - val_binary_accuracy: 0.8562\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4575 - AUC: 0.9209 - binary_accuracy: 0.8383 - val_loss: 0.4493 - val_AUC: 0.9277 - val_binary_accuracy: 0.8550\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4571 - AUC: 0.9218 - binary_accuracy: 0.8397 - val_loss: 0.4491 - val_AUC: 0.9291 - val_binary_accuracy: 0.8556\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4567 - AUC: 0.9226 - binary_accuracy: 0.8396 - val_loss: 0.4486 - val_AUC: 0.9293 - val_binary_accuracy: 0.8603\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4562 - AUC: 0.9234 - binary_accuracy: 0.8426 - val_loss: 0.4484 - val_AUC: 0.9306 - val_binary_accuracy: 0.8575\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4559 - AUC: 0.9241 - binary_accuracy: 0.8411 - val_loss: 0.4480 - val_AUC: 0.9312 - val_binary_accuracy: 0.8622\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4554 - AUC: 0.9250 - binary_accuracy: 0.8450 - val_loss: 0.4479 - val_AUC: 0.9315 - val_binary_accuracy: 0.8597\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4550 - AUC: 0.9256 - binary_accuracy: 0.8448 - val_loss: 0.4471 - val_AUC: 0.9314 - val_binary_accuracy: 0.8631\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4544 - AUC: 0.9257 - binary_accuracy: 0.8467 - val_loss: 0.4475 - val_AUC: 0.9330 - val_binary_accuracy: 0.8616\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4540 - AUC: 0.9277 - binary_accuracy: 0.8493 - val_loss: 0.4461 - val_AUC: 0.9325 - val_binary_accuracy: 0.8622\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4536 - AUC: 0.9270 - binary_accuracy: 0.8472 - val_loss: 0.4461 - val_AUC: 0.9334 - val_binary_accuracy: 0.8625\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4531 - AUC: 0.9279 - binary_accuracy: 0.8494 - val_loss: 0.4458 - val_AUC: 0.9341 - val_binary_accuracy: 0.8609\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4525 - AUC: 0.9288 - binary_accuracy: 0.8529 - val_loss: 0.4452 - val_AUC: 0.9342 - val_binary_accuracy: 0.8616\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4521 - AUC: 0.9292 - binary_accuracy: 0.8506 - val_loss: 0.4450 - val_AUC: 0.9348 - val_binary_accuracy: 0.8622\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4516 - AUC: 0.9296 - binary_accuracy: 0.8520 - val_loss: 0.4447 - val_AUC: 0.9355 - val_binary_accuracy: 0.8622\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4513 - AUC: 0.9304 - binary_accuracy: 0.8529 - val_loss: 0.4442 - val_AUC: 0.9352 - val_binary_accuracy: 0.8622\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4509 - AUC: 0.9304 - binary_accuracy: 0.8543 - val_loss: 0.4442 - val_AUC: 0.9360 - val_binary_accuracy: 0.8644\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4506 - AUC: 0.9310 - binary_accuracy: 0.8547 - val_loss: 0.4440 - val_AUC: 0.9364 - val_binary_accuracy: 0.8644\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4503 - AUC: 0.9312 - binary_accuracy: 0.8544 - val_loss: 0.4437 - val_AUC: 0.9365 - val_binary_accuracy: 0.8634\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4501 - AUC: 0.9317 - binary_accuracy: 0.8555 - val_loss: 0.4435 - val_AUC: 0.9369 - val_binary_accuracy: 0.8641\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4498 - AUC: 0.9324 - binary_accuracy: 0.8568 - val_loss: 0.4432 - val_AUC: 0.9371 - val_binary_accuracy: 0.8644\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4496 - AUC: 0.9322 - binary_accuracy: 0.8562 - val_loss: 0.4429 - val_AUC: 0.9367 - val_binary_accuracy: 0.8656\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4493 - AUC: 0.9324 - binary_accuracy: 0.8570 - val_loss: 0.4434 - val_AUC: 0.9375 - val_binary_accuracy: 0.8647\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4494 - AUC: 0.9329 - binary_accuracy: 0.8577 - val_loss: 0.4431 - val_AUC: 0.9377 - val_binary_accuracy: 0.8653\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4490 - AUC: 0.9336 - binary_accuracy: 0.8575 - val_loss: 0.4427 - val_AUC: 0.9375 - val_binary_accuracy: 0.8659\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4489 - AUC: 0.9331 - binary_accuracy: 0.8577 - val_loss: 0.4430 - val_AUC: 0.9385 - val_binary_accuracy: 0.8675\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4488 - AUC: 0.9338 - binary_accuracy: 0.8578 - val_loss: 0.4428 - val_AUC: 0.9387 - val_binary_accuracy: 0.8669\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4487 - AUC: 0.9338 - binary_accuracy: 0.8575 - val_loss: 0.4427 - val_AUC: 0.9387 - val_binary_accuracy: 0.8675\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4487 - AUC: 0.9345 - binary_accuracy: 0.8587 - val_loss: 0.4422 - val_AUC: 0.9383 - val_binary_accuracy: 0.8691\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4485 - AUC: 0.9341 - binary_accuracy: 0.8584 - val_loss: 0.4424 - val_AUC: 0.9387 - val_binary_accuracy: 0.8672\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4483 - AUC: 0.9349 - binary_accuracy: 0.8582 - val_loss: 0.4424 - val_AUC: 0.9391 - val_binary_accuracy: 0.8681\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4483 - AUC: 0.9347 - binary_accuracy: 0.8588 - val_loss: 0.4421 - val_AUC: 0.9388 - val_binary_accuracy: 0.8681\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4481 - AUC: 0.9352 - binary_accuracy: 0.8587 - val_loss: 0.4420 - val_AUC: 0.9393 - val_binary_accuracy: 0.8697\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4481 - AUC: 0.9352 - binary_accuracy: 0.8605 - val_loss: 0.4421 - val_AUC: 0.9395 - val_binary_accuracy: 0.8687\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4479 - AUC: 0.9356 - binary_accuracy: 0.8594 - val_loss: 0.4419 - val_AUC: 0.9392 - val_binary_accuracy: 0.8700\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4480 - AUC: 0.9355 - binary_accuracy: 0.8603 - val_loss: 0.4420 - val_AUC: 0.9396 - val_binary_accuracy: 0.8697\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4479 - AUC: 0.9362 - binary_accuracy: 0.8607 - val_loss: 0.4418 - val_AUC: 0.9393 - val_binary_accuracy: 0.8703\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4478 - AUC: 0.9354 - binary_accuracy: 0.8612 - val_loss: 0.4422 - val_AUC: 0.9403 - val_binary_accuracy: 0.8725\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4477 - AUC: 0.9363 - binary_accuracy: 0.8602 - val_loss: 0.4423 - val_AUC: 0.9400 - val_binary_accuracy: 0.8709\n",
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4477 - AUC: 0.9367 - binary_accuracy: 0.8616 - val_loss: 0.4416 - val_AUC: 0.9400 - val_binary_accuracy: 0.8709\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4477 - AUC: 0.9361 - binary_accuracy: 0.8607 - val_loss: 0.4419 - val_AUC: 0.9401 - val_binary_accuracy: 0.8703\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4476 - AUC: 0.9366 - binary_accuracy: 0.8614 - val_loss: 0.4420 - val_AUC: 0.9404 - val_binary_accuracy: 0.8731\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4478 - AUC: 0.9369 - binary_accuracy: 0.8614 - val_loss: 0.4422 - val_AUC: 0.9407 - val_binary_accuracy: 0.8725\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4476 - AUC: 0.9369 - binary_accuracy: 0.8609 - val_loss: 0.4422 - val_AUC: 0.9407 - val_binary_accuracy: 0.8728\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4475 - AUC: 0.9374 - binary_accuracy: 0.8625 - val_loss: 0.4414 - val_AUC: 0.9398 - val_binary_accuracy: 0.8716\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 3ms/step - loss: 0.4476 - AUC: 0.9367 - binary_accuracy: 0.8622 - val_loss: 0.4420 - val_AUC: 0.9407 - val_binary_accuracy: 0.8706\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4475 - AUC: 0.9373 - binary_accuracy: 0.8615 - val_loss: 0.4424 - val_AUC: 0.9413 - val_binary_accuracy: 0.8716\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4475 - AUC: 0.9375 - binary_accuracy: 0.8616 - val_loss: 0.4418 - val_AUC: 0.9406 - val_binary_accuracy: 0.8712\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 3ms/step - loss: 0.4474 - AUC: 0.9378 - binary_accuracy: 0.8626 - val_loss: 0.4418 - val_AUC: 0.9402 - val_binary_accuracy: 0.8706\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9374 - binary_accuracy: 0.8618 - val_loss: 0.4424 - val_AUC: 0.9413 - val_binary_accuracy: 0.8716\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4475 - AUC: 0.9375 - binary_accuracy: 0.8620 - val_loss: 0.4419 - val_AUC: 0.9413 - val_binary_accuracy: 0.8719\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9379 - binary_accuracy: 0.8623 - val_loss: 0.4418 - val_AUC: 0.9410 - val_binary_accuracy: 0.8728\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9381 - binary_accuracy: 0.8621 - val_loss: 0.4417 - val_AUC: 0.9409 - val_binary_accuracy: 0.8728\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4475 - AUC: 0.9376 - binary_accuracy: 0.8612 - val_loss: 0.4417 - val_AUC: 0.9414 - val_binary_accuracy: 0.8731\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4474 - AUC: 0.9381 - binary_accuracy: 0.8633 - val_loss: 0.4419 - val_AUC: 0.9413 - val_binary_accuracy: 0.8744\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9381 - binary_accuracy: 0.8619 - val_loss: 0.4415 - val_AUC: 0.9412 - val_binary_accuracy: 0.8716\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4474 - AUC: 0.9379 - binary_accuracy: 0.8634 - val_loss: 0.4420 - val_AUC: 0.9419 - val_binary_accuracy: 0.8741\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9384 - binary_accuracy: 0.8629 - val_loss: 0.4417 - val_AUC: 0.9413 - val_binary_accuracy: 0.8728\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9382 - binary_accuracy: 0.8620 - val_loss: 0.4417 - val_AUC: 0.9416 - val_binary_accuracy: 0.8731\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9382 - binary_accuracy: 0.8627 - val_loss: 0.4418 - val_AUC: 0.9417 - val_binary_accuracy: 0.8731\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4476 - AUC: 0.9381 - binary_accuracy: 0.8640 - val_loss: 0.4419 - val_AUC: 0.9418 - val_binary_accuracy: 0.8731\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9382 - binary_accuracy: 0.8625 - val_loss: 0.4419 - val_AUC: 0.9416 - val_binary_accuracy: 0.8734\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9387 - binary_accuracy: 0.8635 - val_loss: 0.4415 - val_AUC: 0.9413 - val_binary_accuracy: 0.8719\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9381 - binary_accuracy: 0.8634 - val_loss: 0.4420 - val_AUC: 0.9421 - val_binary_accuracy: 0.8744\n",
      "Epoch 83/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9385 - binary_accuracy: 0.8630 - val_loss: 0.4418 - val_AUC: 0.9417 - val_binary_accuracy: 0.8737\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9383 - binary_accuracy: 0.8634 - val_loss: 0.4421 - val_AUC: 0.9417 - val_binary_accuracy: 0.8734\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9385 - binary_accuracy: 0.8626 - val_loss: 0.4421 - val_AUC: 0.9423 - val_binary_accuracy: 0.8741\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4472 - AUC: 0.9388 - binary_accuracy: 0.8623 - val_loss: 0.4419 - val_AUC: 0.9416 - val_binary_accuracy: 0.8728\n",
      "Epoch 87/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4475 - AUC: 0.9384 - binary_accuracy: 0.8638 - val_loss: 0.4419 - val_AUC: 0.9419 - val_binary_accuracy: 0.8731\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9384 - binary_accuracy: 0.8621 - val_loss: 0.4423 - val_AUC: 0.9423 - val_binary_accuracy: 0.8728\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9386 - binary_accuracy: 0.8629 - val_loss: 0.4422 - val_AUC: 0.9416 - val_binary_accuracy: 0.8731\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9388 - binary_accuracy: 0.8632 - val_loss: 0.4416 - val_AUC: 0.9414 - val_binary_accuracy: 0.8728\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4473 - AUC: 0.9389 - binary_accuracy: 0.8633 - val_loss: 0.4414 - val_AUC: 0.9414 - val_binary_accuracy: 0.8744\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9384 - binary_accuracy: 0.8637 - val_loss: 0.4420 - val_AUC: 0.9417 - val_binary_accuracy: 0.8731\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9383 - binary_accuracy: 0.8625 - val_loss: 0.4420 - val_AUC: 0.9420 - val_binary_accuracy: 0.8731\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9388 - binary_accuracy: 0.8627 - val_loss: 0.4419 - val_AUC: 0.9422 - val_binary_accuracy: 0.8728\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4474 - AUC: 0.9387 - binary_accuracy: 0.8630 - val_loss: 0.4419 - val_AUC: 0.9422 - val_binary_accuracy: 0.8731\n"
     ]
    }
   ],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "# ensorboard --logdir=\"C:\\Users\\Karla\\Documents\\Data Science 2\\Practicals\\05_neural_networks\\logs\\binary_classification_test\"\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
