{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04283daf",
   "metadata": {},
   "source": [
    "# Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9e096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from random import sample\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import CHAID\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "pd.options.display.max_columns=200\n",
    "pd.options.display.max_rows=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17bf419e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\Data\\\\2023_DS2_HW1_data_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loading data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_file \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Data/2023_DS2_HW1_data_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBooking_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of rows:      \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#32647 observations\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of columns:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\Data\\\\2023_DS2_HW1_data_train.csv'"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "data_file = Path(\"/Data/2023_DS2_HW1_data_train.csv\")\n",
    "data = pd.read_csv(data_file, encoding='utf-8', sep = ',', decimal = '.', index_col = 'Booking_ID')\n",
    "\n",
    "print(f'Number of rows:      {data.shape[0]}') #32647 observations\n",
    "print(f'Number of columns:   {data.shape[1]}') #17 possible predictors + 1 target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e792589",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose() # counting predictor are all non-negative\n",
    "data.isna().sum() # xgboost handles NaNs automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee9b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52559c9",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ed7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_target = 'booking_status' #define target\n",
    "data[col_target].value_counts(dropna=False) # NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97394996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobedropped=list(data.loc[data[col_target].isnull()==True].index) # unique rows with NaNs\n",
    "data.drop(labels=tobedropped,axis=0,inplace=True) # deleting those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dda93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define datetime objects\n",
    "col_year = \"arrival_year\"\n",
    "col_month = \"arrival_month\"\n",
    "col_date = \"arrival_date\"\n",
    "data[col_year]=data[col_year].astype(object)\n",
    "data[col_month]=data[col_month].astype(object)\n",
    "data[col_date]=data[col_date].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95695066",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred = list(data.columns)[0:-1] #define predictors\n",
    "cols_pred_num=list(col for col in cols_pred if data[col].dtype!=\"O\") #numerical\n",
    "cols_pred_cat=list(col for col in cols_pred if data[col].dtype==\"O\") #categorical\n",
    "\n",
    "# Moving 0/1 variables\n",
    "cols_pred_num.remove(\"repeated_guest\")\n",
    "cols_pred_num.remove(\"required_car_parking_space\")\n",
    "\n",
    "cols_pred_cat.append(\"repeated_guest\")\n",
    "cols_pred_cat.append(\"required_car_parking_space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd61c1",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa094c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting with stratification by month\n",
    "data['sample']='default'\n",
    "col_sample='sample'\n",
    "month_mask=data[col_month].isna()==False\n",
    "month_na_mask=data[col_month].isna()==True\n",
    "\n",
    "data_train, data_rest = train_test_split(data[month_mask], test_size=0.2, random_state=12, \n",
    "                                         stratify=(data[month_mask][[col_month,col_target]]))\n",
    "data_valid, data_test = train_test_split(data_rest, train_size=0.5, stratify = (data_rest[[col_month,col_target]]),\n",
    "                                         random_state=12)\n",
    "\n",
    "data.loc[data_train.index, 'sample'] = 'train'\n",
    "data.loc[data_valid.index, 'sample'] = 'valid'\n",
    "data.loc[data_test.index, 'sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77fdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define masks\n",
    "train_mask = (data['sample'] == 'train')\n",
    "valid_mask = (data['sample'] == 'valid') \n",
    "test_mask = (data['sample'] == 'test') \n",
    "oot_mask = (data['sample'] == 'oot')  \n",
    "hoot_mask = (data['sample'] == 'hoot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_inf=[]\n",
    "cols_with_neginf=[]\n",
    "for col in cols_pred_num:\n",
    "    if np.any(np.isinf(data[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(cols_with_inf)       \n",
    "for col in cols_pred_num:\n",
    "    if np.any(np.isneginf(data[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(col_with_neginf)\n",
    "#no infinities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feee484",
   "metadata": {},
   "source": [
    "# Mean target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41126202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(dt, predictor, target, alpha = 0.05):\n",
    "    total_cnt = len(dt)\n",
    "    total_cr = np.mean(dt[target])\n",
    "    dt_grp = dt.groupby(predictor).agg(\n",
    "        categ_cr = (target, np.mean),\n",
    "        categ_cnt = (target, len)\n",
    "    )\n",
    "    \n",
    "    dt_grp['categ_freq'] = dt_grp['categ_cnt'] / total_cnt\n",
    "    dt_grp['categ_encoding'] = (dt_grp['categ_freq'] * dt_grp['categ_cr'] + alpha * total_cr) / (dt_grp['categ_freq'] + alpha)\n",
    "    \n",
    "    return dt_grp[['categ_encoding']].to_dict()['categ_encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aa502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cr = np.mean(data[train_mask][col_target])\n",
    "\n",
    "# encode categorical predictors\n",
    "for pred in tqdm(cols_pred_cat):\n",
    "    if len(data[pred].unique()) < 0:\n",
    "        dummies = pd.get_dummies(\n",
    "            data[pred], \n",
    "            prefix = pred,\n",
    "            prefix_sep = '_',\n",
    "            dummy_na = True if data[pred].isnull().sum() > 0 else False,\n",
    "            drop_first = False\n",
    "        )\n",
    "        \n",
    "        for d in dummies.columns:\n",
    "            if d in data.columns:\n",
    "                del data[d]\n",
    "                \n",
    "        data = data.join(dummies)\n",
    "        \n",
    "        for col in dummies.columns:\n",
    "            if col not in cols_pred:\n",
    "                cols_pred.append(col)\n",
    "        \n",
    "        if pred in cols_pred:\n",
    "            cols_pred.remove(pred)\n",
    "    else:\n",
    "        new_vals = mean_target_encoding(\n",
    "            dt=data[train_mask], \n",
    "            predictor=pred, \n",
    "            target=col_target\n",
    "        )\n",
    "\n",
    "        additional_values = set(data[data[pred].notnull()][pred].unique()) - set(new_vals.keys())\n",
    "        for p in additional_values:\n",
    "            new_vals[p] = total_cr\n",
    "\n",
    "        data['MTE_' + pred] = data[pred].replace(new_vals)\n",
    "        \n",
    "        if 'MTE_' + pred not in cols_pred:\n",
    "            cols_pred.append('MTE_' + pred)\n",
    "        \n",
    "        if pred in cols_pred:\n",
    "            cols_pred.remove(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066377f",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84828893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier(\n",
    "    booster=\"gbtree\",\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    verbosity=1,\n",
    "    random_state=12,\n",
    "    importance_type=\"total_gain\",\n",
    "    max_depth=4,\n",
    "    learning_rate=0.15,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    data[train_mask][cols_pred].values,\n",
    "    data[train_mask][col_target].values,\n",
    "    eval_set=[   \n",
    "        (data[train_mask][cols_pred].values, data[train_mask][col_target].values),\n",
    "        (data[test_mask][cols_pred].values, data[test_mask][col_target].values),\n",
    "        (data[valid_mask][cols_pred].values, data[valid_mask][col_target].values) #použitá pro early_stopping\n",
    "    ],\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 30,\n",
    ")\n",
    "\n",
    "evals_result=model.evals_result()\n",
    "evals_result[\"train\"]=evals_result.pop(\"validation_0\")\n",
    "evals_result[\"test\"]=evals_result.pop(\"validation_1\")\n",
    "evals_result[\"valid\"]=evals_result.pop(\"validation_2\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"The Best AUC on Valid:\")\n",
    "print(model.best_score)\n",
    "print(\"\")\n",
    "print(\"Iteration for the Best Score\")\n",
    "print(model.best_iteration)\n",
    "data[\"predicted_cr\"]=model.predict_proba(data[cols_pred])[:,1]\n",
    "data[\"predicted_score\"]=np.log(data[\"predicted_cr\"]/(1-data[\"predicted_cr\"]))\n",
    "\n",
    "# Plot AUC \n",
    "\n",
    "metric = 'auc'\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "total_iteration_count = len(evals_result[list(evals_result.keys())[0]][metric])\n",
    "for sample, vals in evals_result.items():\n",
    "    ax.plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals[metric],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "best_score = model.best_score\n",
    "best_iteration = model.best_iteration+1\n",
    "\n",
    "ax.plot([1, total_iteration_count], [best_score, best_score], color='black', ls='--', lw=1)\n",
    "ax.scatter([best_iteration], [best_score], color = 'black')\n",
    "ax.annotate(\n",
    "    '{:d}; {:0.3f}'.format(best_iteration, best_score), \n",
    "    xy = (best_iteration, best_score), \n",
    "    xytext = (best_iteration,best_score+0.005),\n",
    ")\n",
    "ax.set_xlabel('iteration', color='gray')\n",
    "ax.set_ylabel(metric, color='gray')\n",
    "ax.legend(loc='best')\n",
    "ax.set_title(f'Model training - {metric} curves')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(cols_pred, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:25} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n",
    "# Plot importance\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, cols_pred, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a matrix containg Feature importance = total gain and the name of an according predictor\n",
    "FI=model.feature_importances_\n",
    "FI=[FI,np.array(cols_pred)]\n",
    "FI=pd.DataFrame(FI).transpose()\n",
    "FI.columns=[\"Feature importance\",\"Predictor\"]\n",
    "FI=FI.sort_values(by=[\"Feature importance\"],ascending=True)\n",
    "FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_calibration(dt, col_score, col_target, n_bins = 25):\n",
    "    min_score = dt[col_score].min() - 0.1\n",
    "    max_score = dt[col_score].max() + 0.1\n",
    "    \n",
    "    bins = [round(min_score + i * (max_score - min_score) / n_bins, 2) for i in range(n_bins+1)]\n",
    "    dt = dt.assign(score_bin = pd.cut(dt[col_score], bins = bins, include_lowest = False))\n",
    "    \n",
    "    dt_grp = dt.groupby('score_bin').agg(\n",
    "        bad_cnt = (col_target, sum),\n",
    "        tot_cnt = (col_target, len),\n",
    "        def_rt = (col_target, np.mean),\n",
    "        avg_score = (col_score, np.mean)\n",
    "    )\n",
    "    dt_grp['good_cnt'] = dt_grp['tot_cnt'] - dt_grp['bad_cnt']\n",
    "    dt_grp['bad_cnt_norm'] = dt_grp['bad_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['good_cnt_norm'] = dt_grp['good_cnt'] / dt_grp['tot_cnt']\n",
    "    dt_grp['expected_pd'] = 1 / (1 + np.exp(-dt_grp['avg_score']))\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize = (12,4))\n",
    "    fig.suptitle(col_score)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['bad_cnt'], color = 'salmon', label = 'bads')\n",
    "    axs[0].bar(range(len(dt_grp)), dt_grp['good_cnt'], bottom = dt_grp['bad_cnt'], color = 'lightblue', label = 'goods')\n",
    "    axs[0].set_ylabel('observations count')\n",
    "    axs[0].set_xlabel('score')\n",
    "    axs[0].set_xticks(range(len(dt_grp)))\n",
    "    axs[0].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[0].spines['right'].set_color('gray')\n",
    "    axs[0].spines['top'].set_visible(False)\n",
    "    axs[0].spines['left'].set_color('gray')\n",
    "    axs[0].spines['bottom'].set_color('gray')\n",
    "    axs[0].tick_params(axis='y', colors='gray')\n",
    "    axs[0].tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    ax0l = axs[0].twinx()\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['def_rt'], marker = 'o', color = 'red')\n",
    "    ax0l.plot(range(len(dt_grp)), dt_grp['expected_pd'], color = 'black', ls = '--')\n",
    "    ax0l.set_ylabel('default rate', color = 'red')\n",
    "    \n",
    "    ax0l.spines['right'].set_color('gray')\n",
    "    ax0l.spines['top'].set_visible(False)\n",
    "    ax0l.spines['left'].set_color('gray')\n",
    "    ax0l.spines['bottom'].set_color('gray')\n",
    "    ax0l.tick_params(axis='y', colors='gray')\n",
    "    ax0l.tick_params(axis='x', colors='gray')\n",
    "    \n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['bad_cnt_norm'], color = 'salmon', label = 'bads')\n",
    "    axs[1].bar(range(len(dt_grp)), dt_grp['good_cnt_norm'], bottom = dt_grp['bad_cnt_norm'], color = 'lightblue', label = 'goods')\n",
    "    axs[1].set_ylabel('frequency')\n",
    "    axs[1].set_xlabel('score')\n",
    "    axs[1].set_xticks(range(len(dt_grp)))\n",
    "    axs[1].set_xticklabels(dt_grp.index, rotation = 90)\n",
    "    \n",
    "    axs[1].spines['right'].set_visible(False)\n",
    "    axs[1].spines['top'].set_visible(False)\n",
    "    axs[1].spines['left'].set_color('gray')\n",
    "    axs[1].spines['bottom'].set_color('gray')\n",
    "    axs[1].tick_params(axis='y', colors='gray')\n",
    "    axs[1].tick_params(axis='x', colors='gray')\n",
    "plot_score_calibration(data[test_mask],\"predicted_score\",col_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(predictors):\n",
    "    params={\n",
    "        'eta': 0.15,\n",
    "        'max_depth': 4,\n",
    "        \"subsample\":0.7,\n",
    "        \"colsample_bytree\":0.7,\n",
    "\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic' ,\n",
    "        'booster': 'gbtree',\n",
    "        'tree_method': 'hist',\n",
    "\n",
    "        'base_score': 0.08,\n",
    "\n",
    "        'seed': 12\n",
    "    }\n",
    "\n",
    "    evals_result = {}\n",
    "\n",
    "    booster_mc = xgb.train(\n",
    "        verbose_eval=False,\n",
    "        params = params,\n",
    "        dtrain = xgb.DMatrix(data[train_mask][predictors], data[train_mask][col_target]),\n",
    "        num_boost_round = 1000,\n",
    "        evals = (\n",
    "            (xgb.DMatrix(data[train_mask][predictors], data[train_mask][col_target]), 'train'),\n",
    "            (xgb.DMatrix(data[test_mask][predictors], data[test_mask][col_target]), 'test'),\n",
    "            (xgb.DMatrix(data[valid_mask][predictors], data[valid_mask][col_target]), 'valid')\n",
    "        ),\n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 30\n",
    "    )\n",
    "    \n",
    "    \n",
    "    prediction = booster_mc.predict(xgb.DMatrix(data[test_mask][predictors]))\n",
    "    return roc_auc_score(data[test_mask][col_target], prediction)\n",
    "\n",
    "prediction=model.predict_proba(data[test_mask][cols_pred],iteration_range=(0,model.best_iteration))[:,1]\n",
    "auc_base = roc_auc_score(data[test_mask][col_target], prediction)\n",
    "\n",
    "marginal_contribution = []\n",
    "for pred in tqdm(cols_pred):\n",
    "    auc = fit_model(predictors=[p for p in cols_pred if p != pred])\n",
    "    marginal_contribution.append((pred, auc_base - auc))\n",
    "    \n",
    "marginal_contribution = sorted(marginal_contribution, key=lambda x: x[1], reverse=False)\n",
    "marginal_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.barh(range(len(marginal_contribution)), [imp for p, imp in marginal_contribution])\n",
    "ax.set_yticks(range(len(marginal_contribution)))\n",
    "ax.set_yticklabels([p for p, imp in marginal_contribution])\n",
    "\n",
    "ax.set_title('Feature marginal contribution')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='x', colors='gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b53075",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC=pd.DataFrame(marginal_contribution,columns=[\"Predictor\",\"Marginal Contribution\"])\n",
    "MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FI=model.feature_importances_\n",
    "FI=[FI,np.array(cols_pred)]\n",
    "FI=pd.DataFrame(FI).transpose()\n",
    "FI.columns=[\"Feature importance\",\"Predictor\"]\n",
    "FI=FI.sort_values(by=[\"Feature importance\"],ascending=False)\n",
    "FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6210ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred=list(FI.loc[FI[\"Feature importance\"]>0.027,\"Predictor\"])\n",
    "cols_pred_num=list(col for col in cols_pred if col.startswith(\"MTE\")==False)\n",
    "cols_pred_cat=list(col for col in cols_pred if col.startswith(\"MTE\")==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=xgb.XGBClassifier(\n",
    "    booster=\"gbtree\",\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    verbosity=1,\n",
    "    random_state=12,\n",
    "    importance_type=\"total_gain\",\n",
    "    max_depth=6,\n",
    "    learning_rate=0.25,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.6\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    data[train_mask][cols_pred].values,\n",
    "    data[train_mask][col_target].values,\n",
    "    eval_set=[   \n",
    "        (data[train_mask][cols_pred].values, data[train_mask][col_target].values),\n",
    "        (data[test_mask][cols_pred].values, data[test_mask][col_target].values),\n",
    "        (data[valid_mask][cols_pred].values, data[valid_mask][col_target].values) #použitá pro early_stopping\n",
    "    ],\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 30,\n",
    ")\n",
    "\n",
    "evals_result=final_model.evals_result()\n",
    "evals_result[\"train\"]=evals_result.pop(\"validation_0\")\n",
    "evals_result[\"test\"]=evals_result.pop(\"validation_1\")\n",
    "evals_result[\"valid\"]=evals_result.pop(\"validation_2\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"The Best AUC on Valid:\")\n",
    "print(final_model.best_score)\n",
    "print(\"\")\n",
    "print(\"Iteration for the Best Score\")\n",
    "print(final_model.best_iteration)\n",
    "data[\"predicted_cr\"]=final_model.predict_proba(data[cols_pred])[:,1]\n",
    "data[\"predicted_score\"]=np.log(data[\"predicted_cr\"]/(1-data[\"predicted_cr\"]))\n",
    "\n",
    "# Plot AUC \n",
    "\n",
    "metric = 'auc'\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "total_iteration_count = len(evals_result[list(evals_result.keys())[0]][metric])\n",
    "for sample, vals in evals_result.items():\n",
    "    ax.plot(\n",
    "        range(1, total_iteration_count + 1), \n",
    "        vals[metric],\n",
    "        label=sample\n",
    "    )\n",
    "\n",
    "best_score = final_model.best_score\n",
    "best_iteration = final_model.best_iteration+1\n",
    "\n",
    "ax.plot([1, total_iteration_count], [best_score, best_score], color='black', ls='--', lw=1)\n",
    "ax.scatter([best_iteration], [best_score], color = 'black')\n",
    "ax.annotate(\n",
    "    '{:d}; {:0.3f}'.format(best_iteration, best_score), \n",
    "    xy = (best_iteration, best_score), \n",
    "    xytext = (best_iteration,best_score+0.005),\n",
    ")\n",
    "ax.set_xlabel('iteration', color='gray')\n",
    "ax.set_ylabel(metric, color='gray')\n",
    "ax.legend(loc='best')\n",
    "ax.set_title(f'Model training - {metric} curves')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_color('gray')\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.tick_params(axis='y', colors='gray')\n",
    "ax.tick_params(axis='x', colors='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_file=Path(\"../Data/2023_DS2_HW1_data_test.csv\")\n",
    "data_test=pd.read_csv(data_test_file,sep=\",\",decimal=\".\",index_col=\"Booking_ID\")\n",
    "\n",
    "data_test.describe().transpose()\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aae9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred_test = list(data_test.columns)\n",
    "\n",
    "# Numerical and categorial predictors\n",
    "cols_pred_num_test=list(col for col in cols_pred_test if data_test[col].dtype!=\"O\")\n",
    "cols_pred_cat_test=list(col for col in cols_pred_test if data_test[col].dtype==\"O\")\n",
    "\n",
    "# Moving categorical variables to appropriate cols_pred_test variable\n",
    "\n",
    "cols_pred_num_test.remove(\"repeated_guest\")\n",
    "cols_pred_num_test.remove(\"required_car_parking_space\")\n",
    "cols_pred_num_test.remove(col_year)\n",
    "cols_pred_num_test.remove(col_month)\n",
    "cols_pred_num_test.remove(col_date)\n",
    "\n",
    "cols_pred_cat_test.append(\"repeated_guest\")\n",
    "cols_pred_cat_test.append(\"required_car_parking_space\")\n",
    "cols_pred_cat_test.append(col_year)\n",
    "cols_pred_cat_test.append(col_month)\n",
    "cols_pred_cat_test.append(col_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a531d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_inf=[]\n",
    "cols_with_neginf=[]\n",
    "for col in cols_pred_num_test:\n",
    "    if np.any(np.isinf(data_test[col])):\n",
    "        cols_with_inf.append(col)\n",
    "        print(cols_with_inf)       \n",
    "for col in cols_pred_num_test:\n",
    "    if np.any(np.isneginf(data_test[col])):\n",
    "        cols_with_neginf.append(col)\n",
    "        print(col_with_neginf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6388496",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dr = np.mean(data[train_mask][col_target])\n",
    "\n",
    "# Encode categorical predictors Dummy of MTE, alpha is chosen 0.01 based on previous comment\n",
    "for pred in tqdm(cols_pred_cat_test):\n",
    "    if len(data_test[pred].unique()) < 0:\n",
    "        dummies = pd.get_dummies(\n",
    "            data_test[pred], \n",
    "            prefix = pred,\n",
    "            prefix_sep = '_',\n",
    "            dummy_na = True if data_test[pred].isnull().sum() > 0 else False,\n",
    "            drop_first = False\n",
    "        )\n",
    "        \n",
    "        for d in dummies.columns:\n",
    "            if d in data_test.columns:\n",
    "                del data_test[d]\n",
    "                \n",
    "        data_test = data_test.join(dummies)\n",
    "        \n",
    "        for col in dummies.columns:\n",
    "            if col not in cols_pred_test:\n",
    "                cols_pred_test.append(col)\n",
    "        \n",
    "        if pred in cols_pred_test:\n",
    "            cols_pred_test.remove(pred)\n",
    "    else:\n",
    "        new_vals = mean_target_encoding(\n",
    "            dt=data[train_mask], \n",
    "            predictor=pred, \n",
    "            target=col_target,\n",
    "            alpha=0.01\n",
    "        )\n",
    "\n",
    "        additional_values = set(data_test[data_test[pred].notnull()][pred].unique()) - set(new_vals.keys())\n",
    "        for p in additional_values:\n",
    "            new_vals[p] = total_dr\n",
    "\n",
    "        data_test['MTE_' + pred] = data_test[pred].replace(new_vals)\n",
    "        \n",
    "        if 'MTE_' + pred not in cols_pred_test:\n",
    "            cols_pred_test.append('MTE_' + pred)\n",
    "        \n",
    "        if pred in cols_pred_test:\n",
    "            cols_pred_test.remove(pred)\n",
    "            \n",
    "# data již obsahují jak původní kategoriální veličiny, tak i upravené MTE a dummy proměnné\n",
    "# data[cols_pre] obsahjí pouze nové kategoriální veličiny, tedy MTE a dummy, už by měly všechny obsahovat pouze čísla a NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[cols_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pred_test=list(FI.loc[FI[\"Feature importance\"]>0.027,\"Predictor\"])\n",
    "cols_pred_num_test=list(col for col in cols_pred_test if col.startswith(\"MTE\")==False)\n",
    "cols_pred_cat_test=list(col for col in cols_pred_test if col.startswith(\"MTE\")==True)\n",
    "\n",
    "data_test[col_target]=final_model.predict_proba(data_test[cols_pred_test])[:,1]\n",
    "\n",
    "data_test.loc[data_test[col_target]>0.2,col_target]=1\n",
    "data_test.loc[data_test[col_target]<=0.2,col_target]=0\n",
    "\n",
    "final=pd.DataFrame(data_test[col_target])\n",
    "final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae36ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"final.csv\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
